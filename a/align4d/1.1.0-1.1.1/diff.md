# Comparing `tmp/align4d-1.1.0.tar.gz` & `tmp/align4d-1.1.1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "align4d-1.1.0.tar", last modified: Tue May  9 02:55:18 2023, max compression
+gzip compressed data, was "align4d-1.1.1.tar", last modified: Fri Jan  1 00:00:00 2016, max compression
```

## Comparing `align4d-1.1.0.tar` & `align4d-1.1.1.tar`

### file list

```diff
@@ -1,9 +1,9 @@
--rw-r--r--   0        0        0    10618 2023-05-09 02:51:44.143002 align4d-1.1.0/README.md
--rw-r--r--   0        0        0      759 2023-05-09 00:39:00.052783 align4d-1.1.0/pyproject.toml
--rw-r--r--   0        0        0        0 2023-02-22 15:58:38.000000 align4d-1.1.0/src/align4d/__init__.py
--rw-r--r--   0        0        0     4455 2023-05-09 02:44:24.227663 align4d-1.1.0/src/align4d/align.py
--rw-r--r--   0        0        0    68096 2023-05-06 20:40:24.892372 align4d-1.1.0/src/align4d/align4d.cp310-win_amd64.pyd
--rw-r--r--   0        0        0   170842 2023-05-09 00:37:12.092411 align4d-1.1.0/src/align4d/align4d.cpython-310-darwin.so
--rw-r--r--   0        0        0  1981216 2023-05-06 20:45:55.257222 align4d-1.1.0/src/align4d/align4d.cpython-310-x86_64-linux-gnu.so
--rw-r--r--   0        0        0     1126 2023-05-09 01:39:20.296078 align4d-1.1.0/src/align4d/align4d.py
--rw-r--r--   0        0        0    11280 1970-01-01 00:00:00.000000 align4d-1.1.0/PKG-INFO
+-rw-r--r--   0        0        0    12459 2023-05-20 16:44:18.162866 align4d-1.1.1/README.md
+-rw-r--r--   0        0        0      822 2023-05-20 16:13:04.057429 align4d-1.1.1/pyproject.toml
+-rw-r--r--   0        0        0        0 2023-02-22 15:58:38.000000 align4d-1.1.1/src/align4d/__init__.py
+-rw-r--r--   0        0        0     4646 2023-05-20 16:07:52.747761 align4d-1.1.1/src/align4d/align.py
+-rw-r--r--   0        0        0    68096 2023-05-06 20:40:24.892372 align4d-1.1.1/src/align4d/align4d.cp310-win_amd64.pyd
+-rw-r--r--   0        0        0   170842 2023-05-09 00:37:12.092411 align4d-1.1.1/src/align4d/align4d.cpython-310-darwin.so
+-rw-r--r--   0        0        0  1981216 2023-05-06 20:45:55.257222 align4d-1.1.1/src/align4d/align4d.cpython-310-x86_64-linux-gnu.so
+-rw-r--r--   0        0        0     1126 2023-05-09 01:39:20.296078 align4d-1.1.1/src/align4d/align4d.py
+-rw-r--r--   0        0        0    13184 1970-01-01 00:00:00.000000 align4d-1.1.1/PKG-INFO
```

### Comparing `align4d-1.1.0/README.md` & `align4d-1.1.1/PKG-INFO`

 * *Files 24% similar despite different names*

```diff
@@ -1,208 +1,243 @@
+Metadata-Version: 2.1
+Name: align4d
+Version: 1.1.1
+Summary: align4d: Multi-sequence alignment tools for aligning ASR and Speaker Diarization result
+Author-email: Peilin Wu <pwu54@emory.edu>
+Requires-Python: >=3.10
+Description-Content-Type: text/markdown
+Classifier: Programming Language :: Python :: 3
+Classifier: License :: OSI Approved :: Apache Software License
+Classifier: Operating System :: Microsoft :: Windows :: Windows 10
+Classifier: Operating System :: Microsoft :: Windows :: Windows 11
+Classifier: Operating System :: MacOS :: MacOS X
+Classifier: Operating System :: POSIX :: Linux
+Project-URL: Bug Tracker, https://github.com/emorynlp/align4d/issues
+Project-URL: Homepage, https://github.com/emorynlp/align4d
+
 # User Instruction
 
 ## Introduction
 
-Align4d is a powerful Python package used for aligning text results from Speaker Diarization and Speech Recognition. This user manual provides a step-by-step guide on how to install, use and troubleshoot the package.
+**align4d** is a powerful Python package used for aligning text results from Speaker Diarization and Speech Recognition to gold standard transcript, especially when there are overlappings between speakers. This user manual provides a step-by-step guide on how to install, use and troubleshoot the package.
+
+## Mechanism
+
+The **align4d** uses global alignment alignment that is a multi-sequence variant of Needleman-Wunsch algorithm to align hypothesis (results generated by Speaker Diarization and Speech Recognition models) to reference (usually gold standard transcript, which will be separated into multiple sequence if there are multiple speakers). The alignment happens on the token level. For long sequence the **align4d** will automatically separate the sequence into smaller segments, align them separately by finding the absolute aligned parts (called barriers), and finally assemble them together. 
+
+The **align4d** uses Levenshtein Distance as the measurement of the similarity between tokens while doing alignment. There can be 4 situations between each position of alignment:
+
+1. Fully match. Two tokens are exactly the same (Levenshtein Distance is 0).
+2. Partially match. Two tokens are not exactly the same but the Levenshtein Distance between them are within a boundary.
+3. Mismatch. Two tokens are different and the Levenshtein Distance between them exceed the boundary.
+4. Gap. Only one token is present because it is aligned to a gap (insertion or deletion of tokens).
 
 ## Installation
 
-To install Align4d, you need to have Python version 3.10 or higher. Follow these steps:
+To install **align4d**, you need to have Python version 3.10 or higher. Follow these steps:
 
 1. Open your terminal or command prompt.
 2. Type in the following command: `pip install align4d`
 3. Wait for the package to download and install.
 
 ## Usage
 
 ### Importing Align4d
 
 To use Align4d in your Python code, you need to import it. Here's how:
 
 ```python
-from align4d import align4d
+from align4d import align
 ```
 
-### Aligning Short Text Results
+### Aligning Text Results
+
+Align4d can align results from Speaker Diarization and Speech Recognition. For simple and straight forward usage, the function can be used like this:
+
+```python
+aligned_result = align.align(hypothesis, reference)
+```
 
-Align4d can align short text (less than 100 tokens) results from Speaker Diarization and Speech Recognition. Here's how to use it:
+Here's the overview of all parameters of the function:
 
 ```python
-aligned_result = align4d.align_without_segment(hypothesis, reference, reference_speaker_label)
+aligned_result = align.align(hypothesis: str | list[str], reference: list[list[str]], partial_bound: int = 2, segment_length: int = None, barrier_length: int = None, strip_punctuation: bool = True)
 ```
 
-The `align_without_segment()` function takes in three parameters:
+The `align()` function takes in 6 parameters, the `hypothesis` and `reference` are required and the other 4 of them are optional:
 
-1. `hypothesis`: This is a list of strings containing tokenized text . Each string represents a word that is generated from the Speech Recognition model. It is suggested to remove all the punctuations, escape values, and any other characters that is not in the natural language.
+1. `hypothesis`: This is a list of strings or a string containing tokenized text . Each string represents a word that is generated from the Speech Recognition model. It is suggested to remove all the punctuations, escape values, and any other characters that is not in the natural language.
     
     ```python
     hypothesis = ["ok", "I", "am", "a", "fish", "Are", "you", "Hello", "there", "How", "are", "you", "ok"]
+    # or 
+    hypothesis = "ok I am a fish. Are you? Hello there. How are you? ok"
     ```
     
-2. `reference`: This is a list of strings containing tokenized text from the gold standard text. Each string represents a word. It is suggested to remove all the punctuations, escape values, and any other characters that is not in the natural language.
+2. `reference`: This is a nested list of strings containing utterance and speaker labels from the gold standard text. The first string within each secondary list represents the speaker label, the second string represents the utterance. It is suggested to remove all the punctuations, escape values, and any other characters that is not in the natural language.
     
     ```python
-    reference = ["I", "am", "a", "fish", "ok", "Are", "you", "Hello", "there", "How", "are", "you"]
+    reference = [
+        ["A", "I am a fish."],
+        ["B", "okay."],
+        ["C", "Are you?"],
+        ["D", "Hello there."],
+        ["E", "How are you?"]
+    ]
     ```
     
-3. `reference_speaker_label`: This is a list of strings containing the speaker label from the gold standard text. Each string represents a word. It is suggested to remove all the punctuations, escape values, and any other characters that is not in the natural language.
+3. `partial_bound`: This is an integer that specifies the boundary between partially match and mismatch in terms of the Levenshtein Distance between the two tokens in comparison. This is an optional parameter and the default value is 2.
+4. `segment_length`: This is a integer that specifies the minimum length of each segment in terms of the number of hypothesis tokens. By providing `segment_length` and `barrier_length` the program can perform manual segmentation before actual alignment for long sequence based on the provided parameters. 
+    
+    If `segment_length` and `barrier_length` are not provided and the hypothesis length in terms of tokens is over 100, the program will automatically search the optimal `segment_length` between 30 and 120 and the following message will appear while doing alignment:
     
     ```python
-    reference_speaker_label = ["A", "A", "A", "A", "B", "C", "C", "D", "D", "E", "E", "E"]
+    segment length: 30 max hypothesis length: 13 max reference length: 12
+    segment length: 31 max hypothesis length: 13 max reference length: 12
+    segment length: 32 max hypothesis length: 13 max reference length: 12
+    ...
+    ...
+    segment length: 117 max hypothesis length: 13 max reference length: 12
+    segment length: 118 max hypothesis length: 13 max reference length: 12
+    segment length: 119 max hypothesis length: 13 max reference length: 12
+    optimal length: 119 optimal barrier length: 6
     ```
     
-
-The `align_without_segment()` function returns a nested list of strings containing the aligned results. The first list of strings is the hypothesis list. The rest of the lists are the reference lists separated according to the provided speaker label. In each list, each word is aligned to the positions that have the same index and the gap is denoted as “-”.
-
-```python
-align_result = align4d.align_without_segment(hypothesis, reference, reference_speaker_label)
-for row in align_result:
-    print(row)
-```
-
-Output from `align_without_segment()` : 
-
-```python
-# content in align_result
-[['ok', 'I', 'am', 'a', 'fish', 'Are', 'you', 'Hello', 'there', 'How', 'are', 'you', 'ok']
-['-', 'I', 'am', 'a', 'fish', '-', '-', '-', '-', '-', '-', '-', '-']
-['ok', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', 'Are', 'you', '-', '-', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', '-', '-', 'Hello', 'there', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', '-', '-', '-', '-', 'How', 'are', 'you', '-']]
-```
+    If `segment_length` and `barrier_length` are not provided and the hypothesis length in terms of tokens is lower than 100, no segmentation will be performed.
+    
+    If `segment_length` and `barrier_length` are provided and both are integers less than or equal to 0, no segmentation will be performed.
+    
+    It is strongly suggested to perform auto or manual segmentation when the input sequence are long otherwise the alignment may fail because of RAM space limit.
+    
+    It is important that the `segment_length` and `barrier_length` need to be provided together to perform manual segmentation otherwise an Exception will be raised.
+    
+    ```python
+    Exception: Segment length or barrier length parameter incorrect or missing.
+    ```
+    
+5. `barrier_length`: This is an integer that specifies the length of parts in terms of number of tokens used to detect the absolute aligned parts. This is an optional parameter and the default value is 6 if the parameter is not specified. By providing `segment_length` and `barrier_length` the program can perform manual segmentation before actual alignment for long sequence based on the provided parameters.
+    
+    It is important that the `segment_length` and `barrier_length` need to be provided together to perform manual segmentation otherwise an Exception will be raised.
+    
+    ```python
+    Exception: Segment length or barrier length parameter incorrect or missing.
+    ```
+    
+6. `strip_punctuation`: This is an boolean that specifies if the **align4d** will strip all punctuation in the hypothesis and reference to provide more accurate alignment result or not. The default is set to **True** and the output will provide alignment with the original punctuation. 
 
 At this stage, the alignment function will also print out the relative information for alignment calculation, including the size of the total matrix used for storing scores for alignment, the number of speakers, the maximum score in the matrix, and the time for computation.
 
 ```python
- matrix size: 14 5 2 3 3 4  total cell: 5040 speaker num: 5 cell max score: 24
+ matrix size: 14 5 2 3 3 4  total cell: 5040 speaker num: 5 cell max score: 21
 time: 0
 ```
 
-### Aligning Long Text Results
-
-For longer text result from Speaker Diarization and Speech Recognition, we can use `align_with_auto_segment()` function. Under this situation, the `align_without_segment()` function may result in too long computation time and too large memory usage.
-
-```
-aligned_result = align4d.align_with_auto_segment(hypothesis, reference, reference_speaker_label)
-```
-
-The `align_with_auto_segment()` function requires the exact same parameters as the `align_without_segment()`. It performs automatic segmentation to slice the long text results into segments by detecting the absolute aligned parts between the hypothesis and reference sequences.
-
-The output will be in the same form as the `align_without_segment()`. However, in addition to the information for alignment calculation, it will also print out the relative information for computing the optimal parameters for auto segmentation.
+The `align()` function returns a dictionary containing the aligned results. The hypothesis will be the list of strings (tokens) as the value for the key “hypothesis”. The reference will be separated into multiple sequences according to the provided speaker label, where each sequence will be a list of strings (tokens) as the value for the key of their speaker labels. All the reference sequences will be contained in a secondary dictionary as the value for the key “reference” in the primary dictionary. In each list, each token is aligned to the positions that have the same index and the gap is denoted as “” (empty string). If there is punctuation in the input, the punctuation will be preserved in the output.
 
 ```python
-segment length: 30 max hypothesis length: 13 max reference length: 12
-segment length: 31 max hypothesis length: 13 max reference length: 12
-segment length: 32 max hypothesis length: 13 max reference length: 12
-...
-...
-segment length: 117 max hypothesis length: 13 max reference length: 12
-segment length: 118 max hypothesis length: 13 max reference length: 12
-segment length: 119 max hypothesis length: 13 max reference length: 12
-optimal length: 119 optimal barrier length: 6
- matrix size: 14 5 2 3 3 4  total cell: 5040 speaker num: 5 cell max score: 24
-time: 0
-```
+import json
 
-Output from `align_with_auto_segment()` : 
-
-```python
-# content in align_result
-[['ok', 'I', 'am', 'a', 'fish', 'Are', 'you', 'Hello', 'there', 'How', 'are', 'you', 'ok']
-['-', 'I', 'am', 'a', 'fish', '-', '-', '-', '-', '-', '-', '-', '-']
-['ok', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', 'Are', 'you', '-', '-', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', '-', '-', 'Hello', 'there', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', '-', '-', '-', '-', 'How', 'are', 'you', '-']]
+hypothesis = "ok I am a fish. Are you? Hello there. How are you? ok"
+reference = [
+        ["A", "I am a fish. "],
+        ["B", "okay. "],
+        ["C", "Are you? "],
+        ["D", "Hello there. "],
+        ["E", "How are you? "]
+]
+align_result = align.align(hypothesis, reference)
+print(json.dumps(output, indent=4))
 ```
 
-### Aligning with Manual Segmentation
-
-In case of `align_with_auto_segment()` failed during the automatic segmentation, you can manually tune the segmentation by specifying the parameters for segmentation using `align_with_manual_segment()`.
-
-The `align_with_manual_segment()` requires five parameters, the first three are the `hypothesis`, `reference`, and `reference_speaker_label` in the exact same format. The rest two parameters are:
-
-1. `segment_length`: This is a int that specifies the minimum length of each segment. For `align_with_auto_segment()` the program will search the optimal `segment_length` between 30 and 120.
-2. `barrier_length`: This is a int that specifies the length of parts used to detect the absolute aligned parts. For `align_with_auto_segment()` the `barrier_length` is set to 6.
-
-```python
-align_result = align4d.align_with_manual_segment(hypo, ref, ref_speaker_label, 100, 6)
-```
-
-With manually specifying the parameters for segmentation, the program will not display the relative information for computing the optimal parameters for auto segmentation. The output will remain the same format as the `align_without_segment()`:
-
-```python
- matrix size: 14 5 2 3 3 4  total cell: 5040 speaker num: 5 cell max score: 24
-time: 0
-```
+Sample output from `align()` : 
 
 ```python
 # content in align_result
-[['ok', 'I', 'am', 'a', 'fish', 'Are', 'you', 'Hello', 'there', 'How', 'are', 'you', 'ok']
-['-', 'I', 'am', 'a', 'fish', '-', '-', '-', '-', '-', '-', '-', '-']
-['ok', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', 'Are', 'you', '-', '-', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', '-', '-', 'Hello', 'there', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', '-', '-', '-', '-', 'How', 'are', 'you', '-']]
+{
+		"hypothesis": ['ok', 'I', 'am', 'a', 'fish.', 'Are', 'you?', 'Hello', 'there.', 'How', 'are', 'you?', 'ok'],
+    "reference": {
+        "A": ['', 'I', 'am', 'a', 'fish.', '', '', '', '', '', '', '', ''],
+        "B": ['okay.', '', '', '', '', '', '', '', '', '', '', '', ''],
+        "C": ['', '', '', '', '', 'Are', 'you?', '', '', '', '', '', ''],
+        "D": ['', '', '', '', '', '', '', 'Hello', 'there.', '', '', '', ''],
+        "E": ['', '', '', '', '', '', '', '', '', 'How', 'are', 'you?', '']
+    }
+}
 ```
 
 ### Retrieve token match result
 
-Based on the alignment result, this tool provide function to retrieve the matching result (fully match, partially match, mismatch, gap) for each token. Use `get_token_match_result()`.
+Based on the alignment result, this tool provide function to retrieve the matching result (fully match, partially match, mismatch, gap) for each token. Use `get_token_match_result()` to retrieve the token level matching result.
 
-The criterion for determining the matching result are the following:
+The criterion for determining the matching result are the following (also mentioned in the **Mechanism**):
 
-1. fully match: edit distance = 0
-2. partially match: edit distance = 1
-3. mismatch: edit distance ≥ 2
+1. fully match: Levenshtein Distance = 0
+2. partially match: Levenshtein Distance ≤ boundary (default to be 2)
+3. mismatch: Levenshtein Distance > boundary (default to be 2)
 4. gap: aligned to a gap
 
-The `get_token_match_result()` requires one parameter, the `align_result` which is the direct return value from the previous three alignment functions. 
+The `get_token_match_result()` requires 2 parameter, the `align_result` which is the direct return value from the previous three alignment functions, and an optional parameter `partial_bound` which must be the same as the `partial_bound` used in `align()` function. 
 
 ```python
-aligned_result = align4d.align_with_auto_segment(hypothesis, reference, reference_speaker_label)
-token_match_result = align4d.get_token_match_result(align_result)
+hypothesis = "ok I am a fish. Are you? Hello there. How are you? ok"
+reference = [
+        ["A", "I am a fish. "],
+        ["B", "okay. "],
+        ["C", "Are you? "],
+        ["D", "Hello there. "],
+        ["E", "How are you? "]
+]
+align_result = align.align(hypothesis, reference)
+token_match_result = align.get_token_match_result(align_result)
+print(token_match_result)
 ```
 
 The return value is a list of strings that shows the token matching result and can either be fully match, partially match, mismatch, or gap.
 
 ```python
 # possible output for get_token_match_result()
-['mismatch', 'mismatch', 'gap', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match']
+['mismatch', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'gap']
 ```
 
 ### Retrieve mapping from reference to hypothesis
 
 Based on the alignment result, this tool provide function to retrieve the mapping from each token in the reference sequences to the hypothesis sequence. Each index shows the relative position (index) in the hypothesis sequence of the non-gap token (fully match, partially match, or mismatch) from the separated reference sequences. If the index is -1, it means that the current token does not aligned to any token in the hypothesis (align to a gap).
 
-To achieve this, use function `get_align_indices()`. This function requires one parameter, the `align_result` which is the direct return value from the previous three alignment functions. 
+To achieve this, use function `get_align_indices()`. This function requires one parameter, the `align_result` which is the direct return value from the previous `align()` function. 
 
 ```python
-hypothesis = ["ok", "I", "am", "a", "fish", "Are", "you", "Hello", "there", "How", "are", "you", "ok"]
-reference = ["I", "am", "a", "fish", "ok", "Are", "you", "Hello", "there", "How", "are", "you"]
-reference_speaker_label = ["A", "A", "A", "A", "B", "C", "C", "D", "D", "E", "E", "E"
-aligned_result = align4d.align_with_auto_segment(hypothesis, reference, reference_speaker_label)
+hypothesis = "ok I am a fish. Are you? Hello there. How are you? ok"
+reference = [
+        ["A", "I am a fish. "],
+        ["B", "okay. "],
+        ["C", "Are you? "],
+        ["D", "Hello there. "],
+        ["E", "How are you? "]
+]
+align_result = align.align(hypothesis, reference)
 align_indices = align4d.get_token_match_result(align_result)
+print(align_indices)
 ```
 
-The return value is a 2d nested list of integers that shows the mapping between tokens from separated reference to hypothesis.
+The return value is a dictionary containing list of integers that shows the mapping between tokens from separated reference to hypothesis. The integers are the indices of the tokens in reference sequence map to the hypothesis sequence (for example, the first token in sequence “C” is mapped to the token in hypothesis with index 5).
 
 ```python
 # possible output
-align_indices = [[1, 2, 3, 4], [0], [5, 6], [7, 8], [9, 10, 11]]
+{
+		'A': [1, 2, 3, 4], 
+		'B': [0], 
+		'C': [5, 6], 
+		'D': [7, 8], 
+		'E': [9, 10, 11]
+}
 ```
 
 ## Troubleshooting
 
 If you encounter any issues while using Align4d, try the following:
 
 1. Make sure you have installed Python version 3.10 or higher.
 2. Make sure you have installed the latest version of Align4d.
 3. Check the input data to make sure it is in the correct format.
     1. The length of the `reference` and `reference_speaker_label` needs to be the same.
     2. All the input strings must be encoded in the utf-8 format.
 4. For short conversation (hypothesis length ≤ 100), please use `align_without_segment()`.
-
-## Conclusion
-
-Align4d is a powerful Python package that can be used to align text results from Speaker Diarization and Speech Recognition. With this user manual, you should be able to install, use and troubleshoot the package with ease.
```

### Comparing `align4d-1.1.0/pyproject.toml` & `align4d-1.1.1/pyproject.toml`

 * *Files 20% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 [build-system]
 requires = ["flit_core>=3.4"]
 build-backend = "flit_core.buildapi"
 
 [project]
 name = "align4d"
-version = "1.1.0"
+version = "1.1.1"
 authors = [
   { name="Peilin Wu", email="pwu54@emory.edu" },
 ]
-description = "Test package for align4d"
+description = "align4d: Multi-sequence alignment tools for aligning ASR and Speaker Diarization result"
 readme = "README.md"
 requires-python = ">=3.10"
 classifiers = [
     "Programming Language :: Python :: 3",
     "License :: OSI Approved :: Apache Software License",
     "Operating System :: Microsoft :: Windows :: Windows 10",
     "Operating System :: Microsoft :: Windows :: Windows 11",
```

### Comparing `align4d-1.1.0/src/align4d/align.py` & `align4d-1.1.1/src/align4d/align.py`

 * *Files 6% similar despite different names*

```diff
@@ -72,15 +72,19 @@
         align_result.append(value)
     TRANS = str.maketrans('', '', string.punctuation)
     align_result = [[token.translate(TRANS) for token in row] for row in align_result]
     align_result = [[token if token != '' else '-' for token in row] for row in align_result]
     return align4d.get_token_match_result(align_result, partial_bound)
 
 
-def get_align_indices(output: dict) -> list[list[int]]:
+def get_align_indices(output: dict) -> dict:
     align_result = [output["hypothesis"]]
     for value in output["reference"].values():
         align_result.append(value)
     TRANS = str.maketrans('', '', string.punctuation)
     align_result = [[token.translate(TRANS) for token in row] for row in align_result]
     align_result = [[token if token != '' else '-' for token in row] for row in align_result]
-    return align4d.get_align_indices(align_result)
+    align_indices_list = align4d.get_align_indices(align_result)
+    align_indices = {}
+    for index, speaker_label in enumerate(output["reference"].keys()):
+        align_indices[speaker_label] = align_indices_list[index]
+    return align_indices
```

### Comparing `align4d-1.1.0/src/align4d/align4d.cpython-310-darwin.so` & `align4d-1.1.1/src/align4d/align4d.cpython-310-darwin.so`

 * *Files identical despite different names*

### Comparing `align4d-1.1.0/src/align4d/align4d.cpython-310-x86_64-linux-gnu.so` & `align4d-1.1.1/src/align4d/align4d.cpython-310-x86_64-linux-gnu.so`

 * *Files identical despite different names*

### Comparing `align4d-1.1.0/src/align4d/align4d.py` & `align4d-1.1.1/src/align4d/align4d.py`

 * *Files identical despite different names*

### Comparing `align4d-1.1.0/PKG-INFO` & `align4d-1.1.1/README.md`

 * *Files 19% similar despite different names*

```diff
@@ -1,224 +1,227 @@
-Metadata-Version: 2.1
-Name: align4d
-Version: 1.1.0
-Summary: Test package for align4d
-Author-email: Peilin Wu <pwu54@emory.edu>
-Requires-Python: >=3.10
-Description-Content-Type: text/markdown
-Classifier: Programming Language :: Python :: 3
-Classifier: License :: OSI Approved :: Apache Software License
-Classifier: Operating System :: Microsoft :: Windows :: Windows 10
-Classifier: Operating System :: Microsoft :: Windows :: Windows 11
-Classifier: Operating System :: MacOS :: MacOS X
-Classifier: Operating System :: POSIX :: Linux
-Project-URL: Bug Tracker, https://github.com/emorynlp/align4d/issues
-Project-URL: Homepage, https://github.com/emorynlp/align4d
-
 # User Instruction
 
 ## Introduction
 
-Align4d is a powerful Python package used for aligning text results from Speaker Diarization and Speech Recognition. This user manual provides a step-by-step guide on how to install, use and troubleshoot the package.
+**align4d** is a powerful Python package used for aligning text results from Speaker Diarization and Speech Recognition to gold standard transcript, especially when there are overlappings between speakers. This user manual provides a step-by-step guide on how to install, use and troubleshoot the package.
+
+## Mechanism
+
+The **align4d** uses global alignment alignment that is a multi-sequence variant of Needleman-Wunsch algorithm to align hypothesis (results generated by Speaker Diarization and Speech Recognition models) to reference (usually gold standard transcript, which will be separated into multiple sequence if there are multiple speakers). The alignment happens on the token level. For long sequence the **align4d** will automatically separate the sequence into smaller segments, align them separately by finding the absolute aligned parts (called barriers), and finally assemble them together. 
+
+The **align4d** uses Levenshtein Distance as the measurement of the similarity between tokens while doing alignment. There can be 4 situations between each position of alignment:
+
+1. Fully match. Two tokens are exactly the same (Levenshtein Distance is 0).
+2. Partially match. Two tokens are not exactly the same but the Levenshtein Distance between them are within a boundary.
+3. Mismatch. Two tokens are different and the Levenshtein Distance between them exceed the boundary.
+4. Gap. Only one token is present because it is aligned to a gap (insertion or deletion of tokens).
 
 ## Installation
 
-To install Align4d, you need to have Python version 3.10 or higher. Follow these steps:
+To install **align4d**, you need to have Python version 3.10 or higher. Follow these steps:
 
 1. Open your terminal or command prompt.
 2. Type in the following command: `pip install align4d`
 3. Wait for the package to download and install.
 
 ## Usage
 
 ### Importing Align4d
 
 To use Align4d in your Python code, you need to import it. Here's how:
 
 ```python
-from align4d import align4d
+from align4d import align
 ```
 
-### Aligning Short Text Results
+### Aligning Text Results
+
+Align4d can align results from Speaker Diarization and Speech Recognition. For simple and straight forward usage, the function can be used like this:
+
+```python
+aligned_result = align.align(hypothesis, reference)
+```
 
-Align4d can align short text (less than 100 tokens) results from Speaker Diarization and Speech Recognition. Here's how to use it:
+Here's the overview of all parameters of the function:
 
 ```python
-aligned_result = align4d.align_without_segment(hypothesis, reference, reference_speaker_label)
+aligned_result = align.align(hypothesis: str | list[str], reference: list[list[str]], partial_bound: int = 2, segment_length: int = None, barrier_length: int = None, strip_punctuation: bool = True)
 ```
 
-The `align_without_segment()` function takes in three parameters:
+The `align()` function takes in 6 parameters, the `hypothesis` and `reference` are required and the other 4 of them are optional:
 
-1. `hypothesis`: This is a list of strings containing tokenized text . Each string represents a word that is generated from the Speech Recognition model. It is suggested to remove all the punctuations, escape values, and any other characters that is not in the natural language.
+1. `hypothesis`: This is a list of strings or a string containing tokenized text . Each string represents a word that is generated from the Speech Recognition model. It is suggested to remove all the punctuations, escape values, and any other characters that is not in the natural language.
     
     ```python
     hypothesis = ["ok", "I", "am", "a", "fish", "Are", "you", "Hello", "there", "How", "are", "you", "ok"]
+    # or 
+    hypothesis = "ok I am a fish. Are you? Hello there. How are you? ok"
     ```
     
-2. `reference`: This is a list of strings containing tokenized text from the gold standard text. Each string represents a word. It is suggested to remove all the punctuations, escape values, and any other characters that is not in the natural language.
+2. `reference`: This is a nested list of strings containing utterance and speaker labels from the gold standard text. The first string within each secondary list represents the speaker label, the second string represents the utterance. It is suggested to remove all the punctuations, escape values, and any other characters that is not in the natural language.
     
     ```python
-    reference = ["I", "am", "a", "fish", "ok", "Are", "you", "Hello", "there", "How", "are", "you"]
+    reference = [
+        ["A", "I am a fish."],
+        ["B", "okay."],
+        ["C", "Are you?"],
+        ["D", "Hello there."],
+        ["E", "How are you?"]
+    ]
     ```
     
-3. `reference_speaker_label`: This is a list of strings containing the speaker label from the gold standard text. Each string represents a word. It is suggested to remove all the punctuations, escape values, and any other characters that is not in the natural language.
+3. `partial_bound`: This is an integer that specifies the boundary between partially match and mismatch in terms of the Levenshtein Distance between the two tokens in comparison. This is an optional parameter and the default value is 2.
+4. `segment_length`: This is a integer that specifies the minimum length of each segment in terms of the number of hypothesis tokens. By providing `segment_length` and `barrier_length` the program can perform manual segmentation before actual alignment for long sequence based on the provided parameters. 
+    
+    If `segment_length` and `barrier_length` are not provided and the hypothesis length in terms of tokens is over 100, the program will automatically search the optimal `segment_length` between 30 and 120 and the following message will appear while doing alignment:
     
     ```python
-    reference_speaker_label = ["A", "A", "A", "A", "B", "C", "C", "D", "D", "E", "E", "E"]
+    segment length: 30 max hypothesis length: 13 max reference length: 12
+    segment length: 31 max hypothesis length: 13 max reference length: 12
+    segment length: 32 max hypothesis length: 13 max reference length: 12
+    ...
+    ...
+    segment length: 117 max hypothesis length: 13 max reference length: 12
+    segment length: 118 max hypothesis length: 13 max reference length: 12
+    segment length: 119 max hypothesis length: 13 max reference length: 12
+    optimal length: 119 optimal barrier length: 6
     ```
     
-
-The `align_without_segment()` function returns a nested list of strings containing the aligned results. The first list of strings is the hypothesis list. The rest of the lists are the reference lists separated according to the provided speaker label. In each list, each word is aligned to the positions that have the same index and the gap is denoted as “-”.
-
-```python
-align_result = align4d.align_without_segment(hypothesis, reference, reference_speaker_label)
-for row in align_result:
-    print(row)
-```
-
-Output from `align_without_segment()` : 
-
-```python
-# content in align_result
-[['ok', 'I', 'am', 'a', 'fish', 'Are', 'you', 'Hello', 'there', 'How', 'are', 'you', 'ok']
-['-', 'I', 'am', 'a', 'fish', '-', '-', '-', '-', '-', '-', '-', '-']
-['ok', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', 'Are', 'you', '-', '-', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', '-', '-', 'Hello', 'there', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', '-', '-', '-', '-', 'How', 'are', 'you', '-']]
-```
+    If `segment_length` and `barrier_length` are not provided and the hypothesis length in terms of tokens is lower than 100, no segmentation will be performed.
+    
+    If `segment_length` and `barrier_length` are provided and both are integers less than or equal to 0, no segmentation will be performed.
+    
+    It is strongly suggested to perform auto or manual segmentation when the input sequence are long otherwise the alignment may fail because of RAM space limit.
+    
+    It is important that the `segment_length` and `barrier_length` need to be provided together to perform manual segmentation otherwise an Exception will be raised.
+    
+    ```python
+    Exception: Segment length or barrier length parameter incorrect or missing.
+    ```
+    
+5. `barrier_length`: This is an integer that specifies the length of parts in terms of number of tokens used to detect the absolute aligned parts. This is an optional parameter and the default value is 6 if the parameter is not specified. By providing `segment_length` and `barrier_length` the program can perform manual segmentation before actual alignment for long sequence based on the provided parameters.
+    
+    It is important that the `segment_length` and `barrier_length` need to be provided together to perform manual segmentation otherwise an Exception will be raised.
+    
+    ```python
+    Exception: Segment length or barrier length parameter incorrect or missing.
+    ```
+    
+6. `strip_punctuation`: This is an boolean that specifies if the **align4d** will strip all punctuation in the hypothesis and reference to provide more accurate alignment result or not. The default is set to **True** and the output will provide alignment with the original punctuation. 
 
 At this stage, the alignment function will also print out the relative information for alignment calculation, including the size of the total matrix used for storing scores for alignment, the number of speakers, the maximum score in the matrix, and the time for computation.
 
 ```python
- matrix size: 14 5 2 3 3 4  total cell: 5040 speaker num: 5 cell max score: 24
+ matrix size: 14 5 2 3 3 4  total cell: 5040 speaker num: 5 cell max score: 21
 time: 0
 ```
 
-### Aligning Long Text Results
-
-For longer text result from Speaker Diarization and Speech Recognition, we can use `align_with_auto_segment()` function. Under this situation, the `align_without_segment()` function may result in too long computation time and too large memory usage.
-
-```
-aligned_result = align4d.align_with_auto_segment(hypothesis, reference, reference_speaker_label)
-```
-
-The `align_with_auto_segment()` function requires the exact same parameters as the `align_without_segment()`. It performs automatic segmentation to slice the long text results into segments by detecting the absolute aligned parts between the hypothesis and reference sequences.
-
-The output will be in the same form as the `align_without_segment()`. However, in addition to the information for alignment calculation, it will also print out the relative information for computing the optimal parameters for auto segmentation.
+The `align()` function returns a dictionary containing the aligned results. The hypothesis will be the list of strings (tokens) as the value for the key “hypothesis”. The reference will be separated into multiple sequences according to the provided speaker label, where each sequence will be a list of strings (tokens) as the value for the key of their speaker labels. All the reference sequences will be contained in a secondary dictionary as the value for the key “reference” in the primary dictionary. In each list, each token is aligned to the positions that have the same index and the gap is denoted as “” (empty string). If there is punctuation in the input, the punctuation will be preserved in the output.
 
 ```python
-segment length: 30 max hypothesis length: 13 max reference length: 12
-segment length: 31 max hypothesis length: 13 max reference length: 12
-segment length: 32 max hypothesis length: 13 max reference length: 12
-...
-...
-segment length: 117 max hypothesis length: 13 max reference length: 12
-segment length: 118 max hypothesis length: 13 max reference length: 12
-segment length: 119 max hypothesis length: 13 max reference length: 12
-optimal length: 119 optimal barrier length: 6
- matrix size: 14 5 2 3 3 4  total cell: 5040 speaker num: 5 cell max score: 24
-time: 0
-```
+import json
 
-Output from `align_with_auto_segment()` : 
-
-```python
-# content in align_result
-[['ok', 'I', 'am', 'a', 'fish', 'Are', 'you', 'Hello', 'there', 'How', 'are', 'you', 'ok']
-['-', 'I', 'am', 'a', 'fish', '-', '-', '-', '-', '-', '-', '-', '-']
-['ok', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', 'Are', 'you', '-', '-', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', '-', '-', 'Hello', 'there', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', '-', '-', '-', '-', 'How', 'are', 'you', '-']]
+hypothesis = "ok I am a fish. Are you? Hello there. How are you? ok"
+reference = [
+        ["A", "I am a fish. "],
+        ["B", "okay. "],
+        ["C", "Are you? "],
+        ["D", "Hello there. "],
+        ["E", "How are you? "]
+]
+align_result = align.align(hypothesis, reference)
+print(json.dumps(output, indent=4))
 ```
 
-### Aligning with Manual Segmentation
-
-In case of `align_with_auto_segment()` failed during the automatic segmentation, you can manually tune the segmentation by specifying the parameters for segmentation using `align_with_manual_segment()`.
-
-The `align_with_manual_segment()` requires five parameters, the first three are the `hypothesis`, `reference`, and `reference_speaker_label` in the exact same format. The rest two parameters are:
-
-1. `segment_length`: This is a int that specifies the minimum length of each segment. For `align_with_auto_segment()` the program will search the optimal `segment_length` between 30 and 120.
-2. `barrier_length`: This is a int that specifies the length of parts used to detect the absolute aligned parts. For `align_with_auto_segment()` the `barrier_length` is set to 6.
-
-```python
-align_result = align4d.align_with_manual_segment(hypo, ref, ref_speaker_label, 100, 6)
-```
-
-With manually specifying the parameters for segmentation, the program will not display the relative information for computing the optimal parameters for auto segmentation. The output will remain the same format as the `align_without_segment()`:
-
-```python
- matrix size: 14 5 2 3 3 4  total cell: 5040 speaker num: 5 cell max score: 24
-time: 0
-```
+Sample output from `align()` : 
 
 ```python
 # content in align_result
-[['ok', 'I', 'am', 'a', 'fish', 'Are', 'you', 'Hello', 'there', 'How', 'are', 'you', 'ok']
-['-', 'I', 'am', 'a', 'fish', '-', '-', '-', '-', '-', '-', '-', '-']
-['ok', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', 'Are', 'you', '-', '-', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', '-', '-', 'Hello', 'there', '-', '-', '-', '-']
-['-', '-', '-', '-', '-', '-', '-', '-', '-', 'How', 'are', 'you', '-']]
+{
+		"hypothesis": ['ok', 'I', 'am', 'a', 'fish.', 'Are', 'you?', 'Hello', 'there.', 'How', 'are', 'you?', 'ok'],
+    "reference": {
+        "A": ['', 'I', 'am', 'a', 'fish.', '', '', '', '', '', '', '', ''],
+        "B": ['okay.', '', '', '', '', '', '', '', '', '', '', '', ''],
+        "C": ['', '', '', '', '', 'Are', 'you?', '', '', '', '', '', ''],
+        "D": ['', '', '', '', '', '', '', 'Hello', 'there.', '', '', '', ''],
+        "E": ['', '', '', '', '', '', '', '', '', 'How', 'are', 'you?', '']
+    }
+}
 ```
 
 ### Retrieve token match result
 
-Based on the alignment result, this tool provide function to retrieve the matching result (fully match, partially match, mismatch, gap) for each token. Use `get_token_match_result()`.
+Based on the alignment result, this tool provide function to retrieve the matching result (fully match, partially match, mismatch, gap) for each token. Use `get_token_match_result()` to retrieve the token level matching result.
 
-The criterion for determining the matching result are the following:
+The criterion for determining the matching result are the following (also mentioned in the **Mechanism**):
 
-1. fully match: edit distance = 0
-2. partially match: edit distance = 1
-3. mismatch: edit distance ≥ 2
+1. fully match: Levenshtein Distance = 0
+2. partially match: Levenshtein Distance ≤ boundary (default to be 2)
+3. mismatch: Levenshtein Distance > boundary (default to be 2)
 4. gap: aligned to a gap
 
-The `get_token_match_result()` requires one parameter, the `align_result` which is the direct return value from the previous three alignment functions. 
+The `get_token_match_result()` requires 2 parameter, the `align_result` which is the direct return value from the previous three alignment functions, and an optional parameter `partial_bound` which must be the same as the `partial_bound` used in `align()` function. 
 
 ```python
-aligned_result = align4d.align_with_auto_segment(hypothesis, reference, reference_speaker_label)
-token_match_result = align4d.get_token_match_result(align_result)
+hypothesis = "ok I am a fish. Are you? Hello there. How are you? ok"
+reference = [
+        ["A", "I am a fish. "],
+        ["B", "okay. "],
+        ["C", "Are you? "],
+        ["D", "Hello there. "],
+        ["E", "How are you? "]
+]
+align_result = align.align(hypothesis, reference)
+token_match_result = align.get_token_match_result(align_result)
+print(token_match_result)
 ```
 
 The return value is a list of strings that shows the token matching result and can either be fully match, partially match, mismatch, or gap.
 
 ```python
 # possible output for get_token_match_result()
-['mismatch', 'mismatch', 'gap', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match']
+['mismatch', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'fully match', 'gap']
 ```
 
 ### Retrieve mapping from reference to hypothesis
 
 Based on the alignment result, this tool provide function to retrieve the mapping from each token in the reference sequences to the hypothesis sequence. Each index shows the relative position (index) in the hypothesis sequence of the non-gap token (fully match, partially match, or mismatch) from the separated reference sequences. If the index is -1, it means that the current token does not aligned to any token in the hypothesis (align to a gap).
 
-To achieve this, use function `get_align_indices()`. This function requires one parameter, the `align_result` which is the direct return value from the previous three alignment functions. 
+To achieve this, use function `get_align_indices()`. This function requires one parameter, the `align_result` which is the direct return value from the previous `align()` function. 
 
 ```python
-hypothesis = ["ok", "I", "am", "a", "fish", "Are", "you", "Hello", "there", "How", "are", "you", "ok"]
-reference = ["I", "am", "a", "fish", "ok", "Are", "you", "Hello", "there", "How", "are", "you"]
-reference_speaker_label = ["A", "A", "A", "A", "B", "C", "C", "D", "D", "E", "E", "E"
-aligned_result = align4d.align_with_auto_segment(hypothesis, reference, reference_speaker_label)
+hypothesis = "ok I am a fish. Are you? Hello there. How are you? ok"
+reference = [
+        ["A", "I am a fish. "],
+        ["B", "okay. "],
+        ["C", "Are you? "],
+        ["D", "Hello there. "],
+        ["E", "How are you? "]
+]
+align_result = align.align(hypothesis, reference)
 align_indices = align4d.get_token_match_result(align_result)
+print(align_indices)
 ```
 
-The return value is a 2d nested list of integers that shows the mapping between tokens from separated reference to hypothesis.
+The return value is a dictionary containing list of integers that shows the mapping between tokens from separated reference to hypothesis. The integers are the indices of the tokens in reference sequence map to the hypothesis sequence (for example, the first token in sequence “C” is mapped to the token in hypothesis with index 5).
 
 ```python
 # possible output
-align_indices = [[1, 2, 3, 4], [0], [5, 6], [7, 8], [9, 10, 11]]
+{
+		'A': [1, 2, 3, 4], 
+		'B': [0], 
+		'C': [5, 6], 
+		'D': [7, 8], 
+		'E': [9, 10, 11]
+}
 ```
 
 ## Troubleshooting
 
 If you encounter any issues while using Align4d, try the following:
 
 1. Make sure you have installed Python version 3.10 or higher.
 2. Make sure you have installed the latest version of Align4d.
 3. Check the input data to make sure it is in the correct format.
     1. The length of the `reference` and `reference_speaker_label` needs to be the same.
     2. All the input strings must be encoded in the utf-8 format.
-4. For short conversation (hypothesis length ≤ 100), please use `align_without_segment()`.
-
-## Conclusion
-
-Align4d is a powerful Python package that can be used to align text results from Speaker Diarization and Speech Recognition. With this user manual, you should be able to install, use and troubleshoot the package with ease.
+4. For short conversation (hypothesis length ≤ 100), please use `align_without_segment()`.
```

