# Comparing `tmp/magicroot-0.1.83-py3-none-any.whl.zip` & `tmp/magicroot-0.1.84-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,14 +1,59 @@
-Zip file size: 92701 bytes, number of entries: 120
--rw-rw-rw-  2.0 fat      780 b- defN 23-Mar-28 08:55 magicroot/__init__.py
--rw-rw-rw-  2.0 fat     1167 b- defN 23-Feb-03 11:42 magicroot/attach.py
--rw-rw-rw-  2.0 fat     7010 b- defN 23-Mar-28 08:55 magicroot/log.py
--rw-rw-rw-  2.0 fat      694 b- defN 23-Feb-03 11:41 magicroot/time.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Feb-16 17:36 magicroot/_saved/__init__.py
--rw-rw-rw-  2.0 fat       81 b- defN 23-Feb-16 17:36 magicroot/_saved/locator.py
+Zip file size: 136268 bytes, number of entries: 175
+-rw-rw-rw-  2.0 fat      872 b- defN 23-May-20 11:30 magicroot/__init__.py
+-rw-rw-rw-  2.0 fat     1232 b- defN 23-May-06 10:25 magicroot/attach.py
+-rw-rw-rw-  2.0 fat     3157 b- defN 23-May-17 19:16 magicroot/cls.py
+-rw-rw-rw-  2.0 fat      423 b- defN 23-May-14 16:55 magicroot/dic.py
+-rw-rw-rw-  2.0 fat      583 b- defN 23-May-17 17:38 magicroot/errors.py
+-rw-rw-rw-  2.0 fat     6992 b- defN 23-May-08 14:28 magicroot/log.py
+-rw-rw-rw-  2.0 fat      265 b- defN 23-May-14 16:55 magicroot/msg.py
+-rw-rw-rw-  2.0 fat      450 b- defN 23-May-18 20:03 magicroot/telegram.py
+-rw-rw-rw-  2.0 fat      694 b- defN 23-May-06 10:22 magicroot/time.py
+-rw-rw-rw-  2.0 fat     1487 b- defN 23-May-06 10:25 magicroot/_beta/PCES.py
+-rw-rw-rw-  2.0 fat      267 b- defN 23-May-06 10:25 magicroot/_beta/__init__.py
+-rw-rw-rw-  2.0 fat      113 b- defN 23-May-06 10:25 magicroot/_beta/databranch/__init__.py
+-rw-rw-rw-  2.0 fat    14982 b- defN 23-May-06 10:25 magicroot/_beta/databranch/database.py
+-rw-rw-rw-  2.0 fat     1491 b- defN 23-May-06 10:25 magicroot/_beta/databranch/database_structures/__analysis_book.py
+-rw-rw-rw-  2.0 fat     3105 b- defN 23-May-06 10:25 magicroot/_beta/databranch/database_structures/__default_analysis.py
+-rw-rw-rw-  2.0 fat      171 b- defN 23-May-06 10:25 magicroot/_beta/databranch/database_structures/__init__.py
+-rw-rw-rw-  2.0 fat     6224 b- defN 23-May-06 10:25 magicroot/_beta/databranch/database_structures/__sources.py
+-rw-rw-rw-  2.0 fat     1235 b- defN 23-May-06 10:25 magicroot/_beta/databranch/database_structures/__table.py
+-rw-rw-rw-  2.0 fat       60 b- defN 23-May-06 10:25 magicroot/_beta/diamondpinky/__init__.py
+-rw-rw-rw-  2.0 fat       59 b- defN 23-May-06 10:25 magicroot/_beta/diamondpinky/balancesheet/__init__.py
+-rw-rw-rw-  2.0 fat     2936 b- defN 23-May-06 10:25 magicroot/_beta/diamondpinky/balancesheet/balance.py
+-rw-rw-rw-  2.0 fat     5096 b- defN 23-May-06 10:25 magicroot/_beta/diamondpinky/balancesheet/balancesheet.py
+-rw-rw-rw-  2.0 fat       33 b- defN 23-May-06 10:25 magicroot/_beta/diamondpinky/events/__init__.py
+-rw-rw-rw-  2.0 fat     2204 b- defN 23-May-06 10:25 magicroot/_beta/diamondpinky/events/events_table.py
+-rw-rw-rw-  2.0 fat      162 b- defN 23-May-06 10:25 magicroot/_beta/fileleaf/__init__.py
+-rw-rw-rw-  2.0 fat     1662 b- defN 23-May-06 10:25 magicroot/_beta/fileleaf/csv.py
+-rw-rw-rw-  2.0 fat      611 b- defN 23-May-06 10:25 magicroot/_beta/fileleaf/directories.py
+-rw-rw-rw-  2.0 fat      815 b- defN 23-May-06 10:25 magicroot/_beta/fileleaf/extensions.py
+-rw-rw-rw-  2.0 fat      299 b- defN 23-May-06 10:25 magicroot/_beta/fileleaf/other.py
+-rw-rw-rw-  2.0 fat      588 b- defN 23-May-06 10:25 magicroot/_beta/fileleaf/path.py
+-rw-rw-rw-  2.0 fat      484 b- defN 23-May-06 10:25 magicroot/_beta/fileleaf/zip.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-May-06 10:25 magicroot/_beta/fileleaf/excel/__init__.py
+-rw-rw-rw-  2.0 fat      210 b- defN 23-May-06 10:25 magicroot/_beta/gardeningtools/__init__.py
+-rw-rw-rw-  2.0 fat      868 b- defN 23-May-06 10:25 magicroot/_beta/gardeningtools/dynamicmethods.py
+-rw-rw-rw-  2.0 fat       55 b- defN 23-May-06 10:25 magicroot/_beta/pysas/__init__.py
+-rw-rw-rw-  2.0 fat     3710 b- defN 23-May-06 10:25 magicroot/_beta/pysas/extract_egp.py
+-rw-rw-rw-  2.0 fat     1282 b- defN 23-May-06 10:25 magicroot/_beta/pysas/sas_tables.py
+-rw-rw-rw-  2.0 fat       63 b- defN 23-May-06 10:25 magicroot/_beta/smartowl/__init__.py
+-rw-rw-rw-  2.0 fat     1379 b- defN 23-May-06 10:25 magicroot/_beta/smartowl/partiallyorderedset.py
+-rw-rw-rw-  2.0 fat     3248 b- defN 23-May-06 10:25 magicroot/_beta/smartowl/sorter.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-May-06 10:25 magicroot/_pub/__init__.py
+-rw-rw-rw-  2.0 fat      262 b- defN 23-May-20 11:31 magicroot/_pub/controler.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-May-06 10:22 magicroot/_saved/__init__.py
+-rw-rw-rw-  2.0 fat       81 b- defN 23-May-06 10:22 magicroot/_saved/locator.py
+-rw-rw-rw-  2.0 fat       32 b- defN 23-May-06 10:25 magicroot/_tools/__init__.py
+-rw-rw-rw-  2.0 fat      173 b- defN 23-May-06 10:25 magicroot/_tools/_compare/__init__.py
+-rw-rw-rw-  2.0 fat     2934 b- defN 23-May-06 10:25 magicroot/_tools/_compare/_compare.py
+-rw-rw-rw-  2.0 fat      333 b- defN 23-May-06 10:25 magicroot/_tools/_compare/_create.py
+-rw-rw-rw-  2.0 fat     1554 b- defN 23-May-06 10:25 magicroot/_tools/_compare/_reshape.py
+-rw-rw-rw-  2.0 fat      685 b- defN 23-May-06 10:25 magicroot/_tools/_compare/_select.py
+-rw-rw-rw-  2.0 fat      740 b- defN 23-May-06 10:25 magicroot/_tools/_compare/_types.py
 -rw-rw-rw-  2.0 fat     1487 b- defN 23-Feb-03 11:41 magicroot/beta/PCES.py
 -rw-rw-rw-  2.0 fat      267 b- defN 23-Feb-03 11:41 magicroot/beta/__init__.py
 -rw-rw-rw-  2.0 fat      113 b- defN 23-Feb-03 11:41 magicroot/beta/databranch/__init__.py
 -rw-rw-rw-  2.0 fat    14979 b- defN 23-Feb-16 17:36 magicroot/beta/databranch/database.py
 -rw-rw-rw-  2.0 fat     1491 b- defN 23-Feb-03 11:41 magicroot/beta/databranch/database_structures/__analysis_book.py
 -rw-rw-rw-  2.0 fat     3105 b- defN 23-Feb-03 11:41 magicroot/beta/databranch/database_structures/__default_analysis.py
 -rw-rw-rw-  2.0 fat      171 b- defN 23-Feb-03 11:41 magicroot/beta/databranch/database_structures/__init__.py
@@ -32,91 +77,101 @@
 -rw-rw-rw-  2.0 fat      868 b- defN 23-Feb-03 11:41 magicroot/beta/gardeningtools/dynamicmethods.py
 -rw-rw-rw-  2.0 fat       55 b- defN 23-Feb-03 11:41 magicroot/beta/pysas/__init__.py
 -rw-rw-rw-  2.0 fat     3710 b- defN 23-Feb-03 11:41 magicroot/beta/pysas/extract_egp.py
 -rw-rw-rw-  2.0 fat     1282 b- defN 23-Feb-03 11:41 magicroot/beta/pysas/sas_tables.py
 -rw-rw-rw-  2.0 fat       63 b- defN 23-Feb-03 11:41 magicroot/beta/smartowl/__init__.py
 -rw-rw-rw-  2.0 fat     1379 b- defN 23-Feb-03 11:41 magicroot/beta/smartowl/partiallyorderedset.py
 -rw-rw-rw-  2.0 fat     3248 b- defN 23-Feb-03 11:41 magicroot/beta/smartowl/sorter.py
--rw-rw-rw-  2.0 fat      227 b- defN 23-Mar-28 08:55 magicroot/cp/__init__.py
--rw-rw-rw-  2.0 fat     2884 b- defN 23-Mar-28 08:55 magicroot/cp/_component.py
--rw-rw-rw-  2.0 fat     1158 b- defN 23-Mar-28 08:55 magicroot/cp/_discount.py
--rw-rw-rw-  2.0 fat     4604 b- defN 23-Mar-28 08:55 magicroot/cp/_other_components.py
--rw-rw-rw-  2.0 fat     1928 b- defN 23-Mar-06 12:24 magicroot/cp/_settings.py
--rw-rw-rw-  2.0 fat     5578 b- defN 23-Mar-06 12:24 magicroot/cp/_sm.py
--rw-rw-rw-  2.0 fat      626 b- defN 23-Mar-28 08:55 magicroot/cp/_tec.py
--rw-rw-rw-  2.0 fat      242 b- defN 23-Mar-06 20:14 magicroot/cp/_utils.py
--rw-rw-rw-  2.0 fat      196 b- defN 23-Mar-13 09:47 magicroot/db/__init__.py
+-rw-rw-rw-  2.0 fat      227 b- defN 23-May-06 10:22 magicroot/cp/__init__.py
+-rw-rw-rw-  2.0 fat     2884 b- defN 23-May-06 10:22 magicroot/cp/_component.py
+-rw-rw-rw-  2.0 fat     2324 b- defN 23-May-08 14:28 magicroot/cp/_discount.py
+-rw-rw-rw-  2.0 fat     4625 b- defN 23-May-06 10:22 magicroot/cp/_other_components.py
+-rw-rw-rw-  2.0 fat     1928 b- defN 23-May-06 10:22 magicroot/cp/_settings.py
+-rw-rw-rw-  2.0 fat     5169 b- defN 23-May-20 11:32 magicroot/cp/_sm.py
+-rw-rw-rw-  2.0 fat      626 b- defN 23-May-06 10:22 magicroot/cp/_tec.py
+-rw-rw-rw-  2.0 fat      242 b- defN 23-May-06 10:22 magicroot/cp/_utils.py
+-rw-rw-rw-  2.0 fat      233 b- defN 23-May-14 16:55 magicroot/db/__init__.py
 -rw-rw-rw-  2.0 fat     2347 b- defN 23-Mar-13 09:47 magicroot/db/_template.py
--rw-rw-rw-  2.0 fat    14695 b- defN 23-Apr-14 10:07 magicroot/db/build_sequence.py
+-rw-rw-rw-  2.0 fat    17950 b- defN 23-May-17 17:35 magicroot/db/build_sequence.py
 -rw-rw-rw-  2.0 fat      139 b- defN 23-Feb-03 11:41 magicroot/db/complete_table.py
--rw-rw-rw-  2.0 fat      420 b- defN 23-Feb-03 11:42 magicroot/db/tables.py
--rw-rw-rw-  2.0 fat      293 b- defN 23-Feb-03 11:42 magicroot/db/utils.py
--rw-rw-rw-  2.0 fat      321 b- defN 23-Feb-23 14:51 magicroot/db/_build_sequence_phases/__init__.py
--rw-rw-rw-  2.0 fat     1116 b- defN 23-Feb-03 11:42 magicroot/db/_build_sequence_phases/create_table.py
--rw-rw-rw-  2.0 fat      233 b- defN 23-Feb-03 11:42 magicroot/db/_build_sequence_phases/folders.py
--rw-rw-rw-  2.0 fat    10712 b- defN 23-Mar-29 13:14 magicroot/db/_build_sequence_phases/format_inputs.py
--rw-rw-rw-  2.0 fat     4370 b- defN 23-Mar-29 09:43 magicroot/db/_build_sequence_phases/loading_inputs.py
--rw-rw-rw-  2.0 fat     1651 b- defN 23-Mar-22 14:28 magicroot/db/_build_sequence_phases/saving_outputs.py
--rw-rw-rw-  2.0 fat      358 b- defN 23-Feb-03 11:41 magicroot/db/_build_sequence_phases/set_assumptions.py
--rw-rw-rw-  2.0 fat    14088 b- defN 23-Apr-10 14:52 magicroot/db/_build_sequence_phases/utils.py
--rw-rw-rw-  2.0 fat     1417 b- defN 23-Feb-16 17:36 magicroot/db/_build_sequence_phases/validation_outputs.py
--rw-rw-rw-  2.0 fat       54 b- defN 23-Feb-03 11:41 magicroot/db/_table_types/__init__.py
--rw-rw-rw-  2.0 fat     5778 b- defN 23-Feb-03 11:41 magicroot/db/_table_types/_addlines.py
--rw-rw-rw-  2.0 fat     2014 b- defN 23-Feb-03 11:41 magicroot/db/_table_types/_fillfrom.py
--rw-rw-rw-  2.0 fat      463 b- defN 23-Apr-14 17:30 magicroot/df/__init__.py
+-rw-rw-rw-  2.0 fat      385 b- defN 23-May-14 16:55 magicroot/db/tables.py
+-rw-rw-rw-  2.0 fat     2936 b- defN 23-May-14 16:55 magicroot/db/tutorial.py
+-rw-rw-rw-  2.0 fat      293 b- defN 23-May-06 10:22 magicroot/db/utils.py
+-rw-rw-rw-  2.0 fat      321 b- defN 23-May-06 10:22 magicroot/db/_build_sequence_phases/__init__.py
+-rw-rw-rw-  2.0 fat     1826 b- defN 23-May-06 10:22 magicroot/db/_build_sequence_phases/create_table.py
+-rw-rw-rw-  2.0 fat      233 b- defN 23-May-06 10:22 magicroot/db/_build_sequence_phases/folders.py
+-rw-rw-rw-  2.0 fat    11280 b- defN 23-May-14 16:55 magicroot/db/_build_sequence_phases/format_inputs.py
+-rw-rw-rw-  2.0 fat     5562 b- defN 23-May-15 13:21 magicroot/db/_build_sequence_phases/loading_inputs.py
+-rw-rw-rw-  2.0 fat     1713 b- defN 23-May-06 10:22 magicroot/db/_build_sequence_phases/saving_outputs.py
+-rw-rw-rw-  2.0 fat      376 b- defN 23-May-14 16:55 magicroot/db/_build_sequence_phases/set_assumptions.py
+-rw-rw-rw-  2.0 fat    14369 b- defN 23-May-20 11:31 magicroot/db/_build_sequence_phases/utils.py
+-rw-rw-rw-  2.0 fat     1417 b- defN 23-May-06 10:22 magicroot/db/_build_sequence_phases/validation_outputs.py
+-rw-rw-rw-  2.0 fat       54 b- defN 23-May-06 10:22 magicroot/db/_table_types/__init__.py
+-rw-rw-rw-  2.0 fat     5773 b- defN 23-May-14 16:55 magicroot/db/_table_types/_addlines.py
+-rw-rw-rw-  2.0 fat     2008 b- defN 23-May-14 16:55 magicroot/db/_table_types/_fillfrom.py
+-rw-rw-rw-  2.0 fat      667 b- defN 23-May-14 16:55 magicroot/df/__init__.py
+-rw-rw-rw-  2.0 fat      323 b- defN 23-May-06 10:25 magicroot/df/_allocate.py
 -rw-rw-rw-  2.0 fat      618 b- defN 23-Apr-10 14:52 magicroot/df/_tec.py
--rw-rw-rw-  2.0 fat      253 b- defN 23-Feb-03 11:41 magicroot/df/add.py
+-rw-rw-rw-  2.0 fat      712 b- defN 23-May-08 09:44 magicroot/df/add.py
 -rw-rw-rw-  2.0 fat      323 b- defN 23-Feb-03 11:41 magicroot/df/allocate.py
--rw-rw-rw-  2.0 fat      681 b- defN 23-Apr-14 14:04 magicroot/df/cols.py
--rw-rw-rw-  2.0 fat     2911 b- defN 23-Feb-03 11:41 magicroot/df/compare.py
--rw-rw-rw-  2.0 fat     7358 b- defN 23-Feb-03 11:41 magicroot/df/compute.py
--rw-rw-rw-  2.0 fat      331 b- defN 23-Feb-03 11:41 magicroot/df/count.py
--rw-rw-rw-  2.0 fat      333 b- defN 23-Feb-03 11:41 magicroot/df/create.py
--rw-rw-rw-  2.0 fat     9207 b- defN 23-Apr-10 14:52 magicroot/df/disc.py
--rw-rw-rw-  2.0 fat     2512 b- defN 23-Feb-03 11:41 magicroot/df/discount.py
--rw-rw-rw-  2.0 fat     2522 b- defN 23-Apr-14 17:06 magicroot/df/dt.py
--rw-rw-rw-  2.0 fat     4588 b- defN 23-Feb-03 11:42 magicroot/df/format.py
--rw-rw-rw-  2.0 fat     1607 b- defN 23-Mar-28 08:55 magicroot/df/group.py
--rw-rw-rw-  2.0 fat      236 b- defN 23-Feb-03 11:41 magicroot/df/index.py
--rw-rw-rw-  2.0 fat     1193 b- defN 23-Feb-03 11:41 magicroot/df/melt.py
--rw-rw-rw-  2.0 fat      237 b- defN 23-Feb-03 11:41 magicroot/df/other.py
--rw-rw-rw-  2.0 fat     8701 b- defN 23-Apr-10 14:52 magicroot/df/plot.py
--rw-rw-rw-  2.0 fat      263 b- defN 23-Feb-03 11:41 magicroot/df/remove.py
--rw-rw-rw-  2.0 fat      479 b- defN 23-Apr-10 14:52 magicroot/df/rep.py
--rw-rw-rw-  2.0 fat     1543 b- defN 23-Feb-03 11:41 magicroot/df/reshape.py
--rw-rw-rw-  2.0 fat     1200 b- defN 23-Feb-03 11:41 magicroot/df/sample.py
--rw-rw-rw-  2.0 fat      685 b- defN 23-Feb-03 11:41 magicroot/df/select.py
--rw-rw-rw-  2.0 fat      740 b- defN 23-Feb-03 11:41 magicroot/df/types.py
--rw-rw-rw-  2.0 fat       77 b- defN 23-Apr-14 14:04 magicroot/fs/__init__.py
--rw-rw-rw-  2.0 fat     1617 b- defN 23-Apr-14 14:04 magicroot/fs/_balance_sheet.py
+-rw-rw-rw-  2.0 fat     2919 b- defN 23-May-14 16:55 magicroot/df/cols.py
+-rw-rw-rw-  2.0 fat     2911 b- defN 23-May-06 10:22 magicroot/df/compare.py
+-rw-rw-rw-  2.0 fat     7358 b- defN 23-May-06 10:22 magicroot/df/compute.py
+-rw-rw-rw-  2.0 fat      331 b- defN 23-May-06 10:22 magicroot/df/count.py
+-rw-rw-rw-  2.0 fat      333 b- defN 23-May-06 10:22 magicroot/df/create.py
+-rw-rw-rw-  2.0 fat     8841 b- defN 23-May-06 10:25 magicroot/df/disc.py
+-rw-rw-rw-  2.0 fat     2512 b- defN 23-May-06 10:22 magicroot/df/discount.py
+-rw-rw-rw-  2.0 fat     2511 b- defN 23-May-06 10:22 magicroot/df/dt.py
+-rw-rw-rw-  2.0 fat      996 b- defN 23-May-14 16:55 magicroot/df/find.py
+-rw-rw-rw-  2.0 fat    14114 b- defN 23-May-17 19:47 magicroot/df/format.py
+-rw-rw-rw-  2.0 fat      633 b- defN 23-May-14 16:55 magicroot/df/gen.py
+-rw-rw-rw-  2.0 fat     2039 b- defN 23-May-14 16:55 magicroot/df/group.py
+-rw-rw-rw-  2.0 fat      236 b- defN 23-May-06 10:22 magicroot/df/index.py
+-rw-rw-rw-  2.0 fat      414 b- defN 23-May-14 16:55 magicroot/df/interpolate.py
+-rw-rw-rw-  2.0 fat     1322 b- defN 23-May-14 16:55 magicroot/df/melt.py
+-rw-rw-rw-  2.0 fat      291 b- defN 23-May-06 10:25 magicroot/df/merge.py
+-rw-rw-rw-  2.0 fat      237 b- defN 23-May-06 10:22 magicroot/df/other.py
+-rw-rw-rw-  2.0 fat     8564 b- defN 23-May-20 11:32 magicroot/df/plot.py
+-rw-rw-rw-  2.0 fat      388 b- defN 23-May-06 10:22 magicroot/df/re.py
+-rw-rw-rw-  2.0 fat      263 b- defN 23-May-06 10:22 magicroot/df/remove.py
+-rw-rw-rw-  2.0 fat      602 b- defN 23-May-14 16:55 magicroot/df/rep.py
+-rw-rw-rw-  2.0 fat     1543 b- defN 23-May-06 10:22 magicroot/df/reshape.py
+-rw-rw-rw-  2.0 fat     1200 b- defN 23-May-06 10:22 magicroot/df/sample.py
+-rw-rw-rw-  2.0 fat      685 b- defN 23-May-06 10:22 magicroot/df/select.py
+-rw-rw-rw-  2.0 fat      368 b- defN 23-May-14 16:55 magicroot/df/str.py
+-rw-rw-rw-  2.0 fat     3500 b- defN 23-May-19 15:03 magicroot/df/tec.py
+-rw-rw-rw-  2.0 fat      759 b- defN 23-May-17 17:38 magicroot/df/types.py
+-rw-rw-rw-  2.0 fat      149 b- defN 23-May-09 14:03 magicroot/fs/__init__.py
+-rw-rw-rw-  2.0 fat     5708 b- defN 23-May-15 16:45 magicroot/fs/_balance_sheet.py
 -rw-rw-rw-  2.0 fat       54 b- defN 23-Mar-28 08:55 magicroot/fs/_discount.py
--rw-rw-rw-  2.0 fat       59 b- defN 23-Feb-03 11:41 magicroot/os/__init__.py
--rw-rw-rw-  2.0 fat     1910 b- defN 23-Feb-03 11:41 magicroot/os/file.py
--rw-rw-rw-  2.0 fat     6903 b- defN 23-Mar-28 08:55 magicroot/os/folder.py
--rw-rw-rw-  2.0 fat     5105 b- defN 23-Feb-03 11:41 magicroot/os/navigator.py
--rw-rw-rw-  2.0 fat     2227 b- defN 23-Feb-16 17:36 magicroot/os/parcer_base.py
--rw-rw-rw-  2.0 fat     4766 b- defN 23-Feb-16 17:36 magicroot/os/parcers.py
--rw-rw-rw-  2.0 fat       28 b- defN 23-Feb-03 11:41 magicroot/pd/__init__.py
--rw-rw-rw-  2.0 fat     2292 b- defN 23-Feb-03 11:41 magicroot/pd/dataframe.py
--rw-rw-rw-  2.0 fat      507 b- defN 23-Feb-03 11:41 magicroot/pd/parcers.py
+-rw-rw-rw-  2.0 fat    13110 b- defN 23-May-20 11:32 magicroot/fs/disc.py
+-rw-rw-rw-  2.0 fat       59 b- defN 23-May-06 10:22 magicroot/os/__init__.py
+-rw-rw-rw-  2.0 fat     1911 b- defN 23-May-06 10:25 magicroot/os/file.py
+-rw-rw-rw-  2.0 fat     6904 b- defN 23-May-06 10:25 magicroot/os/folder.py
+-rw-rw-rw-  2.0 fat     5106 b- defN 23-May-06 10:25 magicroot/os/navigator.py
+-rw-rw-rw-  2.0 fat     2102 b- defN 23-May-20 11:32 magicroot/os/parcer_base.py
+-rw-rw-rw-  2.0 fat     4766 b- defN 23-May-06 10:22 magicroot/os/parcers.py
+-rw-rw-rw-  2.0 fat       28 b- defN 23-May-06 10:22 magicroot/pd/__init__.py
+-rw-rw-rw-  2.0 fat     2292 b- defN 23-May-06 10:22 magicroot/pd/dataframe.py
+-rw-rw-rw-  2.0 fat      507 b- defN 23-May-06 10:22 magicroot/pd/parcers.py
 -rw-rw-rw-  2.0 fat       74 b- defN 23-Mar-13 09:47 magicroot/plan/__init__.py
 -rw-rw-rw-  2.0 fat      222 b- defN 23-Feb-16 17:36 magicroot/plan/_graphs.py
 -rw-rw-rw-  2.0 fat      680 b- defN 23-Mar-13 09:47 magicroot/plan/_snapshots.py
 -rw-rw-rw-  2.0 fat    11360 b- defN 23-Apr-10 14:52 magicroot/plan/_tasks.py
 -rw-rw-rw-  2.0 fat        0 b- defN 23-Feb-03 11:41 magicroot/pub/__init__.py
 -rw-rw-rw-  2.0 fat      375 b- defN 23-Feb-03 11:41 magicroot/pub/controler.py
--rw-rw-rw-  2.0 fat       30 b- defN 23-Feb-16 17:36 magicroot/settings/__init__.py
--rw-rw-rw-  2.0 fat      120 b- defN 23-Feb-16 17:36 magicroot/settings/folder.py
+-rw-rw-rw-  2.0 fat       30 b- defN 23-May-06 10:22 magicroot/settings/__init__.py
+-rw-rw-rw-  2.0 fat      120 b- defN 23-May-06 10:22 magicroot/settings/folder.py
 -rw-rw-rw-  2.0 fat       79 b- defN 22-May-11 11:46 magicroot/settings/settings_locator.py
 -rw-rw-rw-  2.0 fat       32 b- defN 23-Mar-28 08:55 magicroot/tools/__init__.py
 -rw-rw-rw-  2.0 fat      173 b- defN 23-Mar-28 08:55 magicroot/tools/_compare/__init__.py
 -rw-rw-rw-  2.0 fat     2934 b- defN 23-Mar-28 08:55 magicroot/tools/_compare/_compare.py
 -rw-rw-rw-  2.0 fat      333 b- defN 23-Mar-28 08:55 magicroot/tools/_compare/_create.py
 -rw-rw-rw-  2.0 fat     1554 b- defN 23-Mar-28 08:55 magicroot/tools/_compare/_reshape.py
 -rw-rw-rw-  2.0 fat      685 b- defN 23-Mar-28 08:55 magicroot/tools/_compare/_select.py
 -rw-rw-rw-  2.0 fat      740 b- defN 23-Mar-28 08:55 magicroot/tools/_compare/_types.py
--rw-rw-rw-  2.0 fat     1090 b- defN 23-May-20 08:04 magicroot-0.1.83.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     1221 b- defN 23-May-20 08:04 magicroot-0.1.83.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-May-20 08:04 magicroot-0.1.83.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       10 b- defN 23-May-20 08:04 magicroot-0.1.83.dist-info/top_level.txt
--rw-rw-r--  2.0 fat    10509 b- defN 23-May-20 08:04 magicroot-0.1.83.dist-info/RECORD
-120 files, 248919 bytes uncompressed, 75947 bytes compressed:  69.5%
+-rw-rw-rw-  2.0 fat     1090 b- defN 23-May-20 11:42 magicroot-0.1.84.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat     1221 b- defN 23-May-20 11:42 magicroot-0.1.84.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-May-20 11:42 magicroot-0.1.84.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       10 b- defN 23-May-20 11:42 magicroot-0.1.84.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat    15529 b- defN 23-May-20 11:42 magicroot-0.1.84.dist-info/RECORD
+175 files, 367039 bytes uncompressed, 111484 bytes compressed:  69.6%
```

## zipnote {}

```diff
@@ -1,25 +1,160 @@
 Filename: magicroot/__init__.py
 Comment: 
 
 Filename: magicroot/attach.py
 Comment: 
 
+Filename: magicroot/cls.py
+Comment: 
+
+Filename: magicroot/dic.py
+Comment: 
+
+Filename: magicroot/errors.py
+Comment: 
+
 Filename: magicroot/log.py
 Comment: 
 
+Filename: magicroot/msg.py
+Comment: 
+
+Filename: magicroot/telegram.py
+Comment: 
+
 Filename: magicroot/time.py
 Comment: 
 
+Filename: magicroot/_beta/PCES.py
+Comment: 
+
+Filename: magicroot/_beta/__init__.py
+Comment: 
+
+Filename: magicroot/_beta/databranch/__init__.py
+Comment: 
+
+Filename: magicroot/_beta/databranch/database.py
+Comment: 
+
+Filename: magicroot/_beta/databranch/database_structures/__analysis_book.py
+Comment: 
+
+Filename: magicroot/_beta/databranch/database_structures/__default_analysis.py
+Comment: 
+
+Filename: magicroot/_beta/databranch/database_structures/__init__.py
+Comment: 
+
+Filename: magicroot/_beta/databranch/database_structures/__sources.py
+Comment: 
+
+Filename: magicroot/_beta/databranch/database_structures/__table.py
+Comment: 
+
+Filename: magicroot/_beta/diamondpinky/__init__.py
+Comment: 
+
+Filename: magicroot/_beta/diamondpinky/balancesheet/__init__.py
+Comment: 
+
+Filename: magicroot/_beta/diamondpinky/balancesheet/balance.py
+Comment: 
+
+Filename: magicroot/_beta/diamondpinky/balancesheet/balancesheet.py
+Comment: 
+
+Filename: magicroot/_beta/diamondpinky/events/__init__.py
+Comment: 
+
+Filename: magicroot/_beta/diamondpinky/events/events_table.py
+Comment: 
+
+Filename: magicroot/_beta/fileleaf/__init__.py
+Comment: 
+
+Filename: magicroot/_beta/fileleaf/csv.py
+Comment: 
+
+Filename: magicroot/_beta/fileleaf/directories.py
+Comment: 
+
+Filename: magicroot/_beta/fileleaf/extensions.py
+Comment: 
+
+Filename: magicroot/_beta/fileleaf/other.py
+Comment: 
+
+Filename: magicroot/_beta/fileleaf/path.py
+Comment: 
+
+Filename: magicroot/_beta/fileleaf/zip.py
+Comment: 
+
+Filename: magicroot/_beta/fileleaf/excel/__init__.py
+Comment: 
+
+Filename: magicroot/_beta/gardeningtools/__init__.py
+Comment: 
+
+Filename: magicroot/_beta/gardeningtools/dynamicmethods.py
+Comment: 
+
+Filename: magicroot/_beta/pysas/__init__.py
+Comment: 
+
+Filename: magicroot/_beta/pysas/extract_egp.py
+Comment: 
+
+Filename: magicroot/_beta/pysas/sas_tables.py
+Comment: 
+
+Filename: magicroot/_beta/smartowl/__init__.py
+Comment: 
+
+Filename: magicroot/_beta/smartowl/partiallyorderedset.py
+Comment: 
+
+Filename: magicroot/_beta/smartowl/sorter.py
+Comment: 
+
+Filename: magicroot/_pub/__init__.py
+Comment: 
+
+Filename: magicroot/_pub/controler.py
+Comment: 
+
 Filename: magicroot/_saved/__init__.py
 Comment: 
 
 Filename: magicroot/_saved/locator.py
 Comment: 
 
+Filename: magicroot/_tools/__init__.py
+Comment: 
+
+Filename: magicroot/_tools/_compare/__init__.py
+Comment: 
+
+Filename: magicroot/_tools/_compare/_compare.py
+Comment: 
+
+Filename: magicroot/_tools/_compare/_create.py
+Comment: 
+
+Filename: magicroot/_tools/_compare/_reshape.py
+Comment: 
+
+Filename: magicroot/_tools/_compare/_select.py
+Comment: 
+
+Filename: magicroot/_tools/_compare/_types.py
+Comment: 
+
 Filename: magicroot/beta/PCES.py
 Comment: 
 
 Filename: magicroot/beta/__init__.py
 Comment: 
 
 Filename: magicroot/beta/databranch/__init__.py
@@ -144,14 +279,17 @@
 
 Filename: magicroot/db/complete_table.py
 Comment: 
 
 Filename: magicroot/db/tables.py
 Comment: 
 
+Filename: magicroot/db/tutorial.py
+Comment: 
+
 Filename: magicroot/db/utils.py
 Comment: 
 
 Filename: magicroot/db/_build_sequence_phases/__init__.py
 Comment: 
 
 Filename: magicroot/db/_build_sequence_phases/create_table.py
@@ -186,14 +324,17 @@
 
 Filename: magicroot/db/_table_types/_fillfrom.py
 Comment: 
 
 Filename: magicroot/df/__init__.py
 Comment: 
 
+Filename: magicroot/df/_allocate.py
+Comment: 
+
 Filename: magicroot/df/_tec.py
 Comment: 
 
 Filename: magicroot/df/add.py
 Comment: 
 
 Filename: magicroot/df/allocate.py
@@ -219,32 +360,47 @@
 
 Filename: magicroot/df/discount.py
 Comment: 
 
 Filename: magicroot/df/dt.py
 Comment: 
 
+Filename: magicroot/df/find.py
+Comment: 
+
 Filename: magicroot/df/format.py
 Comment: 
 
+Filename: magicroot/df/gen.py
+Comment: 
+
 Filename: magicroot/df/group.py
 Comment: 
 
 Filename: magicroot/df/index.py
 Comment: 
 
+Filename: magicroot/df/interpolate.py
+Comment: 
+
 Filename: magicroot/df/melt.py
 Comment: 
 
+Filename: magicroot/df/merge.py
+Comment: 
+
 Filename: magicroot/df/other.py
 Comment: 
 
 Filename: magicroot/df/plot.py
 Comment: 
 
+Filename: magicroot/df/re.py
+Comment: 
+
 Filename: magicroot/df/remove.py
 Comment: 
 
 Filename: magicroot/df/rep.py
 Comment: 
 
 Filename: magicroot/df/reshape.py
@@ -252,26 +408,35 @@
 
 Filename: magicroot/df/sample.py
 Comment: 
 
 Filename: magicroot/df/select.py
 Comment: 
 
+Filename: magicroot/df/str.py
+Comment: 
+
+Filename: magicroot/df/tec.py
+Comment: 
+
 Filename: magicroot/df/types.py
 Comment: 
 
 Filename: magicroot/fs/__init__.py
 Comment: 
 
 Filename: magicroot/fs/_balance_sheet.py
 Comment: 
 
 Filename: magicroot/fs/_discount.py
 Comment: 
 
+Filename: magicroot/fs/disc.py
+Comment: 
+
 Filename: magicroot/os/__init__.py
 Comment: 
 
 Filename: magicroot/os/file.py
 Comment: 
 
 Filename: magicroot/os/folder.py
@@ -339,23 +504,23 @@
 
 Filename: magicroot/tools/_compare/_select.py
 Comment: 
 
 Filename: magicroot/tools/_compare/_types.py
 Comment: 
 
-Filename: magicroot-0.1.83.dist-info/LICENSE
+Filename: magicroot-0.1.84.dist-info/LICENSE
 Comment: 
 
-Filename: magicroot-0.1.83.dist-info/METADATA
+Filename: magicroot-0.1.84.dist-info/METADATA
 Comment: 
 
-Filename: magicroot-0.1.83.dist-info/WHEEL
+Filename: magicroot-0.1.84.dist-info/WHEEL
 Comment: 
 
-Filename: magicroot-0.1.83.dist-info/top_level.txt
+Filename: magicroot-0.1.84.dist-info/top_level.txt
 Comment: 
 
-Filename: magicroot-0.1.83.dist-info/RECORD
+Filename: magicroot-0.1.84.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## magicroot/__init__.py

```diff
@@ -1,21 +1,27 @@
-
+"""
+Jack of all trades... you know the rest
+"""
 # modules
-from . import beta  # old and new code
-from . import cp  # compoment structure (lib code)
+from . import os  # to deal with folders and files
 from . import df  # operations on pandas Series and Dataframes
 from . import fs  # useful functions for financial services
-from . import os  # to deal with folders and files
-from . import time  # time executions
-from . import plan  # project management tools
-from .db import CompleteTable
-from .db import CompleteTable as Table  # Base class for building tables
+from . import plan  # project management _tools
+from . import time  # time function executions
+from . import cls  # to deal with attributes of classes
+from . import telegram
+
+from . import cp  # compoment structure (lib code)
+from . import _beta  # non production code, tests
+
+from .db import Table
+from .db import Table as CompleteTable  # Base class for building tables
 
 from . import settings
-from Modelo_de_Dados_Lusitania.src.modelo_de_dados.base._modules.magicroot.pd.dataframe import DataFrame
 
 # global variables
 import pandas
 import logging
 logging.getLogger(__name__).addHandler(logging.NullHandler())
 
 pandas.options.display.float_format = '{:,.2f}'.format
+# pandas.options.display.date_format = '%Y-%m-%d'
```

## magicroot/attach.py

```diff
@@ -1,7 +1,11 @@
+"""
+Advanced use, probably only useful for internal use
+"""
+
 
 def attachment(cls):
     """
     Class decorator that creates descriptors to attach to classes.
 
     Allows making classes modular
```

## magicroot/log.py

```diff
@@ -1,14 +1,14 @@
 import logging
 from .time import Timer
 from contextlib import contextmanager
 import pandas as pd
 import datetime
 import os
-from .tools import df
+from ._tools import df
 
 
 class Log(logging.Logger):
     line = '/*********************************************************************************************************/'
     half_line_space = '                                                    '
 
     def __init__(self, *args, **kwargs):
@@ -62,21 +62,21 @@
             mgn = '\nThe given tables have the following'
             self.debug(
                 f'{mgn} different types\n{df_types[~common_types]}\n'
                 f'{mgn} common types in the tables they are present \n{df_types[common_types & not_in_all]}\n'
                 f'{mgn} common types in all tables \n{df_types[common_types & ~not_in_all]}\n'
 
             )
-        except AttributeError:
+        except (AttributeError, ValueError):
             pass
 
     def describe(self, *args, names, include="all", datetime_is_numeric=True, **kwargs):
         desc = pd.DataFrame()
         for i, table in enumerate(args):
-            d = table.describe(include=include, datetime_is_numeric=datetime_is_numeric, **kwargs).T
+            d = table.describe(include=include, **kwargs).T
             d = d.assign(Table=names[i], Column=d.index).set_index(['Table', 'Column'])
             desc = pd.concat([desc, d])
         self.debug(f'Describe is shown a below \n {desc}')
 
     def sum(self, *args, names, **kwargs):
         msg = 'Sums of given tables are showned below'
         for i, table in enumerate(args):
@@ -147,15 +147,15 @@
                     # print to file
                     logger.addHandler(hand)
                     # print to console
                     # logger.addHandler(logging.StreamHandler())
                     self.__class__.logger = logger
 
                     if separate_old:
-                        old = log_folder.new('.old')
+                        old = log_folder.new('.Z_Rascunhos')
                         for log in log_folder.files:
                             if name + ' - ' in log or self.name + ' - ' in log:
                                 try:
                                     log_folder.move(old, objs=log)
                                 except PermissionError:
                                     pass
```

## magicroot/cp/_discount.py

```diff
@@ -19,7 +19,31 @@
                     (1 + quotes['QUOTE_FWR_DEN']) ** quotes['FORWARD']
             ).fillna((1 + quotes['QUOTE_FWR_NUM']) ** (quotes['FORWARD'] + 1)) - 1
         quotes = quotes.drop(columns=['QUOTE_FWR_DEN', 'QUOTE_FWR_NUM'])
         quotes = quotes.sort_values(
             [col for col in quotes.columns if col not in [col_mat, 'FORWARD', col_rate]] + [col_mat]
         ).fillna(method='ffill')
         return quotes
+
+
+class ForwardMonth(Component):
+    def run(self, quotes, forward, col_rate='QUOTE_RT', col_mat='MATURITY_DT'):
+        # if isinstance(forward, int):
+        #     quotes['FORWARD'] = forward
+
+        fwr_quotes = quotes.merge(quotes.rename(columns={col_rate: 'QUOTE_FWR_DEN'}).assign(
+                MATURITY_DT=lambda x: x[col_mat] - quotes['FORWARD']
+        ), how='left')
+        quotes = fwr_quotes.merge(quotes.rename(columns={col_rate: 'QUOTE_FWR_NUM'}).assign(
+            MATURITY_DT=lambda x: x[col_mat] - quotes['FORWARD'] + 1
+        ), how='left')
+
+        quotes[col_rate] = \
+            (
+                    (1 + quotes['QUOTE_FWR_NUM']) ** (quotes['FORWARD'] + 0.0849315068493151) /
+                    (1 + quotes['QUOTE_FWR_DEN']) ** quotes['FORWARD']
+            ).fillna((1 + quotes['QUOTE_FWR_NUM']) ** (quotes['FORWARD'] + 0.0849315068493151)) - 1
+        quotes = quotes.drop(columns=['QUOTE_FWR_DEN', 'QUOTE_FWR_NUM'])
+        quotes = quotes.sort_values(
+            [col for col in quotes.columns if col not in [col_mat, 'FORWARD', col_rate]] + [col_mat]
+        ).fillna(method='ffill')
+        return quotes
```

## magicroot/cp/_other_components.py

```diff
@@ -6,14 +6,15 @@
 class AttributeSelector(Component):
     def run(self, *attrs, instance, error=AttributeError):
         for attr in attrs:
             try:
                 return getattr(instance, attr)
             except error:
                 pass
+        raise error
 
 
 class ToDic(Component):
     def run(self, args, func):
         if not isinstance(args, dict):
             return {k: v for k, v in zip(inspect.getfullargspec(func)[0][1:], args)}
         return args
```

## magicroot/cp/_sm.py

```diff
@@ -1,10 +1,9 @@
 import inspect
 
-from Modelo_de_Dados_Lusitania.src.modelo_de_dados.base._modules.magicroot import os
 
 class SM:
     def start(self):
         self.state = self.startState
 
     def step(self, inp):
         (s, o) = self.getNextValues(self.state, inp)
@@ -145,22 +144,20 @@
         # log.debug(msg)
         print(msg)
         return dic
 
 
 class CoaValidation:
     i = {
-        'lus': {'file_name': 'LUS_CoA', 'sheet_name': 'Plano contas IFRS17', 'usecols': 'A:C', 'skiprows': 0},
-        'sas': {'file_name': 'SAS_CoA', 'sheet_name': 'COA Mapping 3.7', 'usecols': 'C:AL', 'skiprows': 8}
+
     }
 
     __call__ = (((CheckAttribute() >> LoadDic()) & LoadDic()) >> LoadFromDic()).__call__
 
 
-CoA = os.home['Lus\\IFRS17\\Motor de Calculo SAS\\Data Model Tables\\Output\\Analysis\\CoA Validation']
 
 
 # LoadInputs = (CheckAttribute() >> LoadDic()) & CoA & ''
 
 # print(LoadInputs(CoaValidation, 'table_inputs', 'inputs_dicionary', 'inputs_dictionary', 'i', 'h'))
```

## magicroot/db/__init__.py

```diff
@@ -1,7 +1,9 @@
-
+"""
+This Module is used to create tables
+"""
 
 from .tables import *
-from .complete_table import CompleteTable
 from ._table_types import *
+from .build_sequence import Table
 from .utils import config_folder
-from ._template import get_table_template, get_table_tutorial
+from .tutorial import get_table_template, get_table_tutorial
```

## magicroot/db/build_sequence.py

```diff
@@ -1,18 +1,25 @@
-
+import pandas as pd
+import threading
 from .tables import *
 from ._build_sequence_phases import *
 import traceback
 import warnings
 from .. import cp
-from ..os import home
+from ..os import Folder
+import os
+from colorama import Fore
+
 
 
 @logged(ref_folder='output')
-class BuildSequenceTable(BuildSequenceTests):
+class Table(BuildSequenceTests):
+
+    sounds = 'matrix'
+    sounds_started = False
 
     load = AggInputs()
     format = Formatter()
     create_module = FreestyleCreate()
     save_module = SavingOutputs()
     validate_module = ValidateOutputs()
     folders = FoldersStorage()
@@ -23,92 +30,118 @@
     formatted_inputs = []
     drop_duplicates = False
     materiality = None
     data_dictionary = None
     config = None
     rename_columns = {}
     schema = []
-    default_extension = '.ftr'
+    default_extension = '.parquet'
     release_extension = '.csv'
 
     def build(
             self, release_to=None, input=None, output=None, config=None, validation_output=None, logs=None,
             logs_backup=None, report_to=None,
             *args, **kwargs
     ):
-
+        self.start_sounds()
         print(f'Creating {self.name} ({self.__class__.__name__})...')
-
+        got_errors = False  # TODO delete
+        error = None
+        df = pd.DataFrame()  # TODO delete
         self.folder_definiton(
             input=input, output=output, config=config, validation_output=validation_output, logs=logs, release_to=release_to, logs_backup=logs_backup, report_to=report_to,
         )
 
         with self.log.section('Process of creating table'):
 
             self._phase('(01/08) Loading Inputs', self.load.run)
 
-            self._phase('(02/08) Formating Inputs', self.format.run, self.load.output)
+            try:
 
-            self._phase('(03/08) Creating Table', self.create_module.run, self.format.output, *args, **kwargs)
+                self._phase('(02/08) Formating Inputs', self.format.run, self.load.output)
 
-            df = self._phase('(04/08) Applying Assumptions', self._phase_set_assumptions, *args, **kwargs)
-            df = df['set_assumption_result']
+                self._phase('(03/08) Creating Table', self.create_module.run, self.format.output, *args, **kwargs)
 
-            with self.log.section('Selecting appropriate schema'):
-                print(f'\t(05/08) Selecting appropriate schema...')
-                if self.schema:
-                    df = self.fill_schema(self._assumptions_table, schema=self.schema)
-                    df = df[self.schema]
-                if self.data_dictionary_module.data_dictionary_schema:
-                    pass
-                else:
-                    try:
-                        self.data_dictionary_module.fill_data_dictionary(df)
-                    except (TableImplementationError, ValueError, AttributeError):
+                df = self._phase('(04/08) Applying Assumptions', self._phase_set_assumptions, *args, **kwargs)
+                df = df['set_assumption_result']
+
+                with self.log.section('Selecting appropriate schema'):
+                    print(f'\t(05/08) Selecting appropriate schema...')
+                    if self.schema:
+                        df = self.fill_schema(self._assumptions_table, schema=self.schema)
+                        df = df[self.schema]
+                    if self.data_dictionary_module.data_dictionary_schema:
                         pass
-                if self.drop_duplicates:
-                    df = df.drop_duplicates()
-                else:
-                    self.log.info('No schema was provided for this table')
+                    else:
+                        try:
+                            self.data_dictionary_module.fill_data_dictionary(df)
+                        except (TableImplementationError, ValueError, AttributeError):
+                            pass
+                    if self.drop_duplicates:
+                        df = df.drop_duplicates()
+                    else:
+                        self.log.info('No schema was provided for this table')
 
-            self._phase('(06/08) Saving Outputs', self.save_module.run, df, release_to=release_to)
+                self._phase('(06/08) Saving Outputs', self.save_module.run, df, release_to=release_to)
 
-            self._phase('(07/08) Validate Outputs', self.validate_module.run, df, *args, **kwargs)
+                self._phase('(07/08) Validate Outputs', self.validate_module.run, df, *args, **kwargs)
+
+            except Exception as e:
+                print(Fore.YELLOW)
+                print('\t\t Error ocurred during excution,' 
+                      'will create reports before printing it')  
+                # warnings.warn(traceback.format_exc())
+                print(Fore.WHITE)  
+                self.log.error(traceback.format_exc())
+                got_errors = True
+                error = e
+                    
 
             with self.log.section('Relevant reports'):
                 try:
                     print(f'\t(08/08) Relevant reports...')
-                    self.relevant_reports(df, *args, **kwargs)
+                    self.relevant_reports(df, *args, **self.format.output, **kwargs)
                 except Exception as e:
-                    warnings.warn('Unable to produce reports, see log for error')
+                    warnings.warn(traceback.format_exc())
                     self.log.error(traceback.format_exc())
-                self.save_excel_log()
                 self.save_reports()
 
-            print(f'\tFinished creating {self.name} ({self.__class__.__name__}).')
+            if got_errors:
+                print(Fore.RED)
+                raise error
+                print(f'\tUnable to create {self.name} ({self.__class__.__name__}).')
+                self.get_user_input()
+                return df
 
+            print(f'\tFinished creating {self.name} ({self.__class__.__name__}).')
         return df
 
+    def get_user_input(self):
+
+        print('Do you want to continue execution [y/n]:')
+        x = input()
+        if 'n' in x:
+            raise SystemExit
+
     def valid(self, output=None, release_to=None, validate=True, *args, **kwargs):
         print(f'Validating {self.name} ({self.__class__.__name__})...')
 
         self.folder_definiton(output=output, release_to=release_to)
         df = self.output.get(self.save_name)
 
         if validate:
             self._phase('Validate Outputs', self.validate_module.run, df, *args, **kwargs)
 
         with self.log.section('Relevant reports'):
             try:
                 print(f'\tRelevant reports...')
                 self.relevant_reports(df, *args, **kwargs)
             except Exception as e:
-                warnings.warn('Unable to produce reports, see log for error')
+                warnings.warn(traceback.format_exc())
                 self.log.error(traceback.format_exc())
-            self.save_excel_log()
             self.save_reports()
 
     def report(self, output=None, release_to=None, *args, **kwargs):
         print(f'Reporting {self.name} ({self.__class__.__name__})...')
         self.output = output
         self.release_to = release_to
         df = output.get(self.save_name)
@@ -117,74 +150,99 @@
             try:
                 print(f'\tRelevant reports...')
                 self.relevant_reports(df, *args, **kwargs)
             except Exception as e:
                 warnings.warn('Unable to produce reports, see log for error')
                 self.log.error(traceback.format_exc())
 
-    def folder_definiton(self, input=None, output=None, config=None, validation_output=None, logs=None, release_to=None, logs_backup=None, report_to=None,):
-        self.report_to = report_to
-        self.release_to = release_to
-        self.output = output if output else self.release_to
-        self.input = input if input else self.output
-        self.config = config or self.config or self.output
-        self.output.new(folder='.dbReports')
+    def folder_definiton(self, input=None, output=None, config=None, validation_output=None, 
+                         logs=None, release_to=None, logs_backup=None, report_to=None,):
+        try:
+            self.report_to = report_to
+            self.release_to = release_to
+            self.output = output if output else self.release_to
+            self.input = input if input else self.output
+            self.config = config or self.config or self.output
+            self.output.new(folder='.dbReports')
+        except AttributeError:
+            print('Error accessing folder possible passed a None paramenter for input or output or'
+                  'typed incorrectly \'input\' or \'output\'')
+            
+
+        if not isinstance(self.release_to, Folder) and self.release_to:
+            raise TypeError('release_to is not a folder')
+        if not isinstance(self.input, Folder):
+            raise TypeError('input is not a folder')
+        if not isinstance(self.output, Folder):
+            raise TypeError('output is not a folder')
+        
 
     def _phase(self, name, func, *args, **kwargs):
         with self.log.section(name):
             print(f'\t{name}...')
             rv = func(*args, **kwargs)
-            self.update_excel_log(rv, name)
-            self.log.report(*rv.values(), names=list(rv.keys()))
+            try:
+                self.update_excel_log(rv, name)
+                self.log.report(*rv.values(), names=list(rv.keys()))
+            except Exception as exc:
+                warn('Unable to report')
+                traceback.print_exception(type(exc), exc, exc.__traceback__)
             return rv
 
     def _phase_set_assumptions(self, *args, **kwargs):
         # df = self.set_assumptions(self._created_table, *args, **kwargs)
         df = self.set_assumptions(self.create_module.output, *args, **kwargs)
         self._assumptions_table = df
         return {'set_assumption_result': df}
 
-    def new(self, report=None, description=None, name=None):
+    def new(self, report=None, description=None, name=None, with_tests=None):
+        report = report.copy()
         if not name:
-            name = 'Rep_' + str(len(self.generated_reports.keys()) + 1)
+            name = ('Rep_' + str(len(self.generated_reports.keys()) + 1))[:31]
         if not description:
             description = name
         report.index.name = description
-        self.generated_reports[name[:31]] = report
+        self.generated_reports[name] = report
+
+        # define testes associated with report
+        if with_tests is not None:
+            if not isinstance(with_tests, dict):
+                with_tests = {name: test for test in with_tests}
+
+            for desc, test in with_tests.items():
+                self.define_test(df=name, pass_test=test, description=desc)
 
     def define_test(self, df, pass_test, description, fail_msg=None, sep='\n\n\t\t\t', *args, **kwargs):
         leng = 0
         mat = None
+        df_str = None
+        state = 'passed'
+
+        if isinstance(df, str):
+            df_str = df
+            df = self.generated_reports[df]
+        if not isinstance(pass_test, pd.Series):
+            pass_test = pass_test(df)
         try:
             assert pass_test.all()
             self.log.debug(sep + f'Testing \'{description}\' passed for all rows')
         except AssertionError:
-            if fail_msg:
-                msg = sep + fail_msg + sep
-            else:
-                len_msg = ''
-                mat_msg = ''
-                sample = ''
-                if len(pass_test) == len(df):
-                    leng = len(df[~pass_test])
-                    leng_all = max(len(df), 1)
-                    len_msg = f'\t{leng} rows or {leng/leng_all :.2%}\n'
+            state = 'failed'
+            if len(pass_test) == len(df):
+                leng = len(df[~pass_test])
+                try:
                     if self.materiality:
                         mat = df.loc[~pass_test, self.materiality].astype(float).abs().sum() if self.materiality else 0
                         mat_all = max(df.loc[:, self.materiality].astype(float).abs().sum(), 1) if self.materiality else 1
-                        mat_msg = f'\t{mat :,.2f} absolute monetary units or {mat/mat_all :.2%}\n' \
+                        mat_msg = f'\t{mat :,.2f} absolute monetary units or {mat/mat_all :.2%}\n'
+                except KeyError:
+                    pass
+                self.new(report=df[~pass_test].sample(min(leng, 10000)), name='Auto_test_' + str(len(self.test_log) + 1))
 
-                        sample = self.log.sample(df[~pass_test], names=['Test'], log=False)
-                msg = sep + \
-                      f'Testing \'{description}\' failed \n' + \
-                      sep + len_msg + sep + mat_msg + sep + f'{sample}' + sep
-
-            self.log.info(msg)
-            warnings.warn(msg)
-        self._update_test_log(df, description, leng, mat=mat)
+        self._update_test_log(df, description, leng, id=str(len(self.test_log) + 1), mat=mat, table=df_str, state=state)
 
     def test_nulls(self, df, columns=None):
         columns = columns if columns else df.columns
         for column in columns:
             self.log.debug(f'Assering that {column} is not null')
             if column in df.columns:
                 self.define_test(
@@ -197,37 +255,55 @@
         try:
             df_new_lines = self.basic_describe(*rv.values(), names=list(rv.keys())).assign(
                 dt=cp.Component.exec_dt,
                 Class=self.__class__.__name__,
                 Phase=phase
             )
             self.excel_log = pd.concat([self.excel_log, cp.df_cols_pull_forward(df_new_lines, ['dt', 'Class', 'Phase'])])
-        except AttributeError:
+        except (AttributeError, ValueError):
             pass
 
-    def save_excel_log(self):
+    def _update_test_log(self, on, description, leng, id=None, mat=None, table=None, state=None):
         try:
-            # home[cp.Settings('cp', 'settings_config')['path']].append_to('phase_log.xlsx',
-            #                                                              with_obj=self.excel_log)
-            self.output['.dbReports'].append_to('phase_log.xlsx', with_obj=self.excel_log)
-        except (PermissionError, pd._config.config.OptionError):
-            print('Unable to save phase log')
+            df_new_lines = pd.DataFrame({
+                'excution_dt': [cp.Component.exec_dt],
+                'user': [self.output.user],
+                'class': [self.__class__.__name__],
+                'table': [table if table else self.name],
+                'id': id,
+                'test_description': [description],
+                'state': [state],
+                'n_rows_that_failed': [leng],
+                'materiality_that_failed': [mat],
+                'materilaty_column_used': [self.materiality],
+                'Total_rows': [len(on)],
+                'Total_columns': [len(on.columns)]
+            })
+            # print(self.test_log.head())
+            self.test_log = pd.concat([self.test_log, df_new_lines])
+        except AttributeError:
+            pass
 
     def save_reports(self):
-        if len(self.generated_reports.keys()) > 0:
-            try:
-                self.output['.dbReports'].new(file=self.name + '.xlsx', with_obj=self.generated_reports)
-            except PermissionError:
-                print('Unable to save phase log')
+        try:
+            if len(self.test_log) > 0:
+                df = self.test_log[self.test_log['state'] == 'failed']
+                if len(df) > 0:
+                    warn(f'The tests below have failed:\n {df}')
+            self.new(report=self.excel_log, name='Auto_phase_log')
+            self.new(report=self.test_log, name='Auto_test_log')
+            self.output['.dbReports'].new(file=self.name + '.xlsx', with_obj=self.generated_reports)
+        except PermissionError:
+            print('Unable to save reports, please check that the file is closed')
 
     @staticmethod
     def basic_describe(*args, names, include="all", datetime_is_numeric=True, **kwargs):
         df = pd.DataFrame()
         for i, table in enumerate(args):
-            d = table.describe(include=include, datetime_is_numeric=datetime_is_numeric, **kwargs).T
+            d = table.describe(include=include, **kwargs).T
             d = d.assign(Table=names[i], Column=d.index)
 
             n = min([len(table), 5])
             samples = table.sample(n=n, **kwargs).T.reset_index(names='Column').assign(Table=names[i])
             samples.columns = ['sample_' + str(i) if col not in ['Column', 'Table'] else col for i, col in
                                enumerate(samples.columns)]
 
@@ -242,36 +318,14 @@
                 samples,
                 how='outer'
             )
             df = pd.concat([df, d])
         df = df[['Table', 'Column'] + [col for col in df.columns if col not in ['Column', 'Table']]]
         return df
 
-    def _update_test_log(self, on, description, leng, mat=None):
-        # folder = home[cp.Settings('cp', 'settings_config')['path']]
-        pass
-        # folder = self.output['.dbReports']
-        # try:
-        #     df = folder.get('test_log.csv', exact_match=True, encoding='latin-1')
-        # except FileNotFoundError:
-        #     df = pd.DataFrame()
-        # df_new_line = pd.DataFrame({
-        #     'datetime': [cp.Component.exec_dt],
-        #     'user': [self.output.user],
-        #     'table': [self.name],
-        #     'class': [self.__class__.__name__],
-        #     'test': [description],
-        #     'rows_for_fail': [leng],
-        #     'materiality_of_fail': [mat],
-        #     'materilaty_column': [self.materiality],
-        #     'rows': [len(on)],
-        #     'columns': [len(on.columns)]
-        # })
-        # folder.new(file='test_log.csv', with_obj=pd.concat([df, df_new_line]), index=False)
-
     @staticmethod
     def format_input(df):
         raise TableImplementationError()
 
     def add_constant_columns(self, df):
         self.log.debug(f'Creating constant columns')
         return df.assign(
@@ -294,17 +348,17 @@
         print(f'\t\tSaved results to {path}')
 
     def release(self, df, release_folder, *args, **kwargs):
         release_folder.new(file=self.save_release_name, with_obj=df, index=False, *args, **kwargs)
         path = os.path.join(release_folder.path, self.save_release_name)
         print(f'\t\tReleased results to {path}')
 
-    def relevant_reports(self, df, *args, **kwargs):
-        self.log.debug('No Relevant reports were set, redefine function \'relevant_reports\' to set')
-        return df
+    # def relevant_reports(self, df, *args, **kwargs):
+    #     self.log.debug('No Relevant reports were set, redefine function \'relevant_reports\' to set')
+    #     return df
 
     def set_assumptions(self, df,  *args, **kwargs):
         self.log.debug('No Assumptions were set')
         return df
 
     @property
     def data_dictionary(self):
@@ -334,33 +388,63 @@
 
     @property
     def applicable_data_dictionary_df(self):
         df = self.data_dictionary_df
         df['ARG'] = df['TABLE'].replace({table: arg for arg, table in self.table_inputs.items()})
         return df[df['ARG'].isin(list(self.table_inputs.keys()) + [self.name])]
 
-    def create(self, *args, **kwargs):
-        return *args, *kwargs
+    def create(self, df, *args, **kwargs):
+        return df
 
     def validate(self, *args, **kwargs):
         pass
 
     def construct(self, *args, **kwargs):
         pass
 
-    def __init__(self, input: mros.Folder = None, output: mros.Folder = None, validation_output: mros.Folder = None):
+    def __init__(self, input: mros.Folder = None, output: mros.Folder = None, validation_output: mros.Folder = None, sounds=None):
         self.input = input
         self.output = output
         self.validation_output = validation_output if validation_output is not None else output
         self.data_dictionary_schema = None
         self.config = None
         self.excel_log = pd.DataFrame()
+        self.test_log = pd.DataFrame()
         self.generated_reports = {}
+        if sounds is not None:
+            Table.sounds = sounds
+        if sounds == 'off':
+            Table.sounds_started = True
 
     def format_date_range(self, begin_dt, end_dt):
         begin_dt = pd.to_datetime(begin_dt, format='%d-%m-%Y')
         self.log.debug(f'Loaded begin_dt {begin_dt}')
 
         end_dt = pd.to_datetime(end_dt, format='%d-%m-%Y')
         self.log.debug(f'Loaded end_dt {end_dt}')
 
         return begin_dt, end_dt
+
+    @classmethod
+    def start_sounds(cls):
+        if not Table.sounds_started:
+            Table.sounds_started = True
+            try:
+                def loopSound():
+                    while True:
+                        from playsound import playsound
+                        playsound(str(cp._settings.path) + '\\sounds\\' + Table.sounds + '.mp3', block=True)
+
+                # providing a name for the thread improves usefulness of error messages.
+                loopThread = threading.Thread(target=loopSound, name='backgroundMusicThread')
+                loopThread.daemon = True  # shut down music thread when the rest of the program exits
+                loopThread.start()
+            except ModuleNotFoundError:
+                warnings.warn('please install \'playsound\' package for full experience ;)')
+            except Exception as e:
+                print('unable to play sounds')
+
+    def relevant_reports(self, *args, **kwargs):
+        pass
+
+    def __contains__(self, item):
+        return dir(self).__contains__(item)
```

## magicroot/db/tables.py

```diff
@@ -9,19 +9,15 @@
     pass
 
 
 class IOTable(ConstructTable):
     pass
 
 
-class Table(IOTable):
-    pass
-
-
-class BuildSequenceProperties(Table):
+class BuildSequenceProperties(IOTable):
     pass
 
 
 class BuildSequenceFunctions(BuildSequenceProperties):
     pass
```

## magicroot/db/_build_sequence_phases/create_table.py

```diff
@@ -1,35 +1,45 @@
 from ...attach import attachment
-from ..utils import TableAttachmentProtocol, TableImplementationError
+from ..utils import TableAttachmentProtocol
 from .. import df
-
-
-class CreateFunctionError(TableImplementationError):
-    pass
+from ... import errors
+import pandas
 
 
 @attachment
 class FreestyleCreate(TableAttachmentProtocol):
 
     def run(self, on, *args, **kwargs):
         df = self.create_error_handling(on, *args, **kwargs)
         if self._instance.constant_columns:
             df = self._instance.add_constant_columns(df)
         self.output = df
         return {'create_table_result': df}
 
     def create_error_handling(self, on, *args, **kwargs):
         try:
-            return self._instance.create(*args, **kwargs, **on)
+            rv = self._instance.create(*args, **kwargs, **on)
+            if isinstance(rv, pandas.DataFrame) or isinstance(rv, dict):
+                return rv
+            raise errors.TableImplementationError(
+                f'\'create\' function in \'{self._instance.__class__.__name__}\''
+                f' should return a pandas.Dataframe or a dict'
+            )
         except ValueError as e:
             if 'If you wish to proceed you should use pd.concat' in str(e):
                 msg = f'You are trying to join columns of different types, ' \
                       f'Check if you are performing a join based on the columns below: ' \
                       f'\n {df.types.different(**on)}'
-                raise CreateFunctionError(msg)
+                raise ValueError(msg)
+            elif 'cannot reindex on an axis with duplicate labels' in str(e):
+                msg = f'Probably one of the columns in the process ends with more than one column with the same name'
+                raise ValueError(msg)
+            elif 'Index contains duplicate entries, cannot reshape' in str(e):
+                msg = f'Probably tried to use \'pd.Dataframe.pivot\' with index with duplicate entries'
+                raise ValueError(msg)
             else:
                 raise e
```

## magicroot/db/_build_sequence_phases/format_inputs.py

```diff
@@ -2,29 +2,40 @@
 import itertools
 import pprint
 from ... import cp
 import pandas as pd
 from ...attach import attachment
 from ..utils import TableAttachmentProtocol, TableImplementationError
 from ...df import format
+from ... import cls
 from .utils import Format
+import warnings
 
 
 @attachment
 class Formatter(TableAttachmentProtocol):
 
     def run(self, on, *args, **kwargs):
         self.formatter_inputs = on
         self.output = on
         self.output = self.format_inputs(on, *args, **kwargs)
         return self.output
 
     columns_formats = {}
 
     @property
+    def f(self):
+        return cls.attribute_selector('f', 'column_formats', instance=self._instance)
+
+    @property
+    def r(self):
+        return cls.attribute_selector('r', 'rename_columns', instance=self._instance)
+
+
+    @property
     def _column_formats(self):
         relevant_column_formats = {}
         items = cp.AttributeSelector()('column_formats', 'f', instance=self._instance)
         if self.column_formats:
             relevant_column_formats = {
                 arg: {
                     ty: [
@@ -35,17 +46,25 @@
             }
         print('--------------------------------------')
         print(relevant_column_formats)
         return relevant_column_formats
 
     def format_inputs(self, on, *args, **kwargs):
         inputs = self.utils.rename_columns_inputs(on, self.rename_columns)
+
+
         try:  # tries to run overwritten format inputs
             self.output = self._format_based_format_input(inputs)
             print('\t\tFormated with \'format_input\'')
+            try:
+                _ = self.f
+                warnings.warn(
+                    'Both \'format_input\' function and \'f\' or \'column_formats\' were defined, ignoring \'f\'')
+            except (TableImplementationError, AttributeError):
+                pass
         except (TableImplementationError, AttributeError):
             try:  # if not defined tries to it own format inputs
                 self.output = self._format_based_on_dic(inputs)
                 print('\t\tFormatted with \'Format dic\'')
             except (TableImplementationError, AttributeError):  # if not possible it does nothing
                 self.output = inputs
         return self.output
```

## magicroot/db/_build_sequence_phases/loading_inputs.py

```diff
@@ -1,70 +1,102 @@
 from warnings import warn
 from functools import cached_property
 import inspect
-from ..tables import BuildSequenceProperties
+
+import pandas as pd
+
 from ...attach import attachment
 from ..utils import TableAttachmentProtocol, TableImplementationError
 from ... import cp
+from ... import df
+from ... import cls
+from ... import dic
 
 
 @attachment
 class AggInputs(TableAttachmentProtocol):
     """
     Defined as a dictionary of the form
     >>> table_inputs = {\'alias\': {\'file_name\': \'some_file_name.csv\', \'config_name\':\'config\'}}
         or
     >>> table_inputs = {\'alias\': \'some_file_name.csv\'}
         or
     >>> table_inputs = {\'alias\': SomeOtherTable()}
     """
     @property
     def _transformed(self):
-        intance_treatment = {
-            BuildSequenceProperties: lambda v: str(v.save_name),
-            str: lambda v: {'file_name': v}
-        }
-
-        input_dic = \
-            cp.AttributeSelector() \
-            >> cp.ToDic(func=self._instance.create) \
-            # ** cp.ApplyBasedOnType(funcs=intance_treatment)
-        agg = input_dic('table_inputs', 'inputs_dicionary', 'inputs_dictionary', 'i', instance=self._instance)
-        x = cp.ApplyBasedOnType(funcs=intance_treatment)
-        dic = {}
-        for key, value in agg.items():
-            dic[key] = x(value)
-        return dic
+        accepted_attrs = ['inputs_dicionary', 'inputs_dictionary', 'table_inputs', 'load_inputs', 'i']
+        defined_attrs = cls.defined(accepted_attrs, self._instance)
+        print(f"\t\tDefined the following input attributes: {defined_attrs}")
+
+        if len(defined_attrs) == 0:
+            warn("\nDid not find a input method please define at least one of the following: "
+                 "['load_inputs', 'table_inputs', 'inputs_dicionary', 'inputs_dictionary', 'i'] \n"
+                 "Continuing assuming: i = ['input_file.xlsx']")
+            return self.build_load_dic(['input_file.xlsx'])
+
+        attrs = [getattr(self._instance, attr) for attr in defined_attrs]
+
+        for i, a in enumerate(attrs):
+            if callable(a):
+                attrs[i] = a()
+            if isinstance(a, str):
+                attrs[i] = [a]
+
+        inputs_dic = {k: self.treat_input_command(v) for d in attrs if isinstance(d, dict) for k, v in d.items()}
+        inputs_list = [self.treat_input_command(v) for l in attrs if isinstance(l, list) for v in l]
+
+        inputs = {}
+        expected_inputs = cls.get_args('create', self._instance)
+        for inp in expected_inputs:
+            try:
+                inputs[inp] = inputs_dic[inp]
+            except (KeyError, TypeError):
+                try:
+                    inputs[inp] = inputs_list.pop(0)
+                except IndexError:
+                    pass
+
+        x = {**{k: v for k, v in inputs.items() if isinstance(v, dict)}, **{k: 'loaded with mapping' for k, v in inputs.items() if isinstance(v, pd.DataFrame)}}
+        print(f"\t\tLoading with the following dic: {x}")
+        return inputs
+
+    def treat_input_command(self, val):
+        try:
+            val = str(val.save_name)
+        except AttributeError:
+            pass
+        if isinstance(val, str):
+            val = {'file_name': val}
+        return val
 
     def load_inputs(self, *args, **kwargs):
         dic, subsequent_arg, msg = {}, False, ''
 
         for arg, obj in self._transformed.items():
-            dic[arg], result = cp.load_file(obj, self.input)
+            if isinstance(obj, dict):
+                dic[arg], result = cp.load_file(obj, self.input)
 
-            if subsequent_arg:
-                msg = msg + f'\n'
-            try:
-                cols = list(dic[arg].columns)
-            except AttributeError:
-                cols = 'Unable to show cols'
-            msg = msg + f'\t\tLoaded \'{arg}\' from {result.path}\n\t\t\t with columns: {cols}'
-            subsequent_arg = True
+                if subsequent_arg:
+                    msg = msg + f'\n'
+                try:
+                    cols = list(dic[arg].columns)
+                except AttributeError:
+                    cols = 'Unable to show cols'
+                msg = msg + f'\t\tLoaded \'{arg}\' from {result.path}\n\t\t\t with columns: {cols}'
+                subsequent_arg = True
+            else:
+                dic[arg] = obj
 
         self._instance.log.debug(msg)
         print(msg)
         return dic
 
     def run(self, *args, **kwargs):
-        try:  # tries to run overwritten load inputs
-            self.output = self._instance.load_inputs()
-            print('\t\tLoaded with \'load_inputs\'')
-        except AttributeError:  # if not defined creates it own load inputs
-            self.output = self.load_inputs()
-            print('\t\tLoaded with \'Load dic\'')
+        self.output = self.load_inputs()
         return self.output
 
 
 @attachment
 class SimplifiedInputs(TableAttachmentProtocol):
     """
     Defined as a dictionary of the form
```

## magicroot/db/_build_sequence_phases/saving_outputs.py

```diff
@@ -16,35 +16,36 @@
         self.save(on)
         if release_to:
             self.release(on, release_to, *args, **kwargs)
         self.update_run_log(on, release_to)
         return {'_saved': on}
 
     def update_run_log(self, on, release_to):
-        folder = home[cp.Settings('cp', 'settings_config')['path']]
-        try:
-            df = folder.get('run_log.csv', exact_match=True)
-        except FileNotFoundError:
-            df = pd.DataFrame()
-        release_path = release_to.path if release_to else ''
-        try:
-            n_col = len(on.columns)
-        except AttributeError:
-            n_col = 0
-        df_new_line = pd.DataFrame({
-            'datetime': [cp.Settings.exec_dt],
-            'user': [self.output.user],
-            'table': [self.name],
-            'class': [self._instance.__class__.__name__],
-            'output_extension': [self.default_extension],
-            'output': [self.output.without_user],
-            'input': [self.input.without_user],
-            'released_to': [release_path],
-            'release_extension': [self.release_extension],
-            'rows': [len(on)],
-            'columns': [n_col]
-        })
-        folder.new(file='run_log.csv', with_obj=pd.concat([df, df_new_line]), index=False)
+        pass
+        # folder = home[cp.Settings('cp', 'settings_config')['path']]
+        # try:
+        #     df = folder.get('run_log.csv', exact_match=True)
+        # except FileNotFoundError:
+        #     df = pd.DataFrame()
+        # release_path = release_to.path if release_to else ''
+        # try:
+        #     n_col = len(on.columns)
+        # except AttributeError:
+        #     n_col = 0
+        # df_new_line = pd.DataFrame({
+        #     'datetime': [cp.Settings.exec_dt],
+        #     'user': [self.output.user],
+        #     'table': [self.name],
+        #     'class': [self._instance.__class__.__name__],
+        #     'output_extension': [self.default_extension],
+        #     'output': [self.output.without_user],
+        #     'input': [self.input.without_user],
+        #     'released_to': [release_path],
+        #     'release_extension': [self.release_extension],
+        #     'rows': [len(on)],
+        #     'columns': [n_col]
+        # })
+        # folder.new(file='run_log.csv', with_obj=pd.concat([df, df_new_line]), index=False)
```

## magicroot/db/_build_sequence_phases/set_assumptions.py

```diff
@@ -1,11 +1,11 @@
 from ..tables import *
 
 
-class AssumptionsTable(Table):
+class AssumptionsTable(BuildSequenceProperties):
 
     def _phase_set_assumptions(self, *args, **kwargs):
         # df = self.set_assumptions(self._created_table, *args, **kwargs)
         df = self.set_assumptions(self.create_module.output, *args, **kwargs)
         self._assumptions_table = df
         return {'set_assumption_result': df}
```

## magicroot/db/_build_sequence_phases/utils.py

```diff
@@ -1,17 +1,17 @@
 from ...attach import attachment
 from ..utils import TableAttachmentProtocol, TableImplementationError
 from .. import df
 import pandas as pd
-import Modelo_de_Dados_Lusitania.src.modelo_de_dados.base._modules.magicroot as mr
 from matplotlib.patches import Patch
 import matplotlib.pyplot as plt
 import numpy as np
 import datetime as dt
 from datetime import timedelta
+from ...errors import TableFormmatingValueError
 import matplotlib.colors as mcolors
 
 
 class Format:
 
     @staticmethod
     def table(table, format_dic):
@@ -21,15 +21,18 @@
             if ty == int:
                 table = Format().as_int(table, cols, errors='ignore')
             if ty == str:
                 table = Format().as_string(table, cols)
             if isinstance(ty, int):
                 table = Format().as_code(table, cols, ty)
             if isinstance(ty, str):
-                table = Format().as_date(table, cols, ty)
+                table = Format().as_date(table, cols, ty, errors='coerce')
+            if isinstance(ty, tuple):
+                for strg in ty:
+                    table = Format().as_date(table, cols, strg, errors='coerce')
 
         return table
 
     @staticmethod
     def with_func(df, columns, func):
         """
         Tranforms the given columns based on the given function
@@ -37,15 +40,18 @@
         :param columns: columns to be transformed
         :param func: function that receives the dataframe and the name of the column to be formated
         :return:
         """
         columns = columns if columns is not None else df.columns
         for column in columns:
             if column in df.columns:
-                df = df.assign(**{column: func(df, column)})
+                try:
+                    df = df.assign(**{column: func(df, column)})
+                except ValueError as e:
+                    raise TableFormmatingValueError(f'Column: {column} could not be formatted')
         # return df.assign(**{column: lambda x: func(x, column) for column in columns if column in df.columns})
         return df
 
     @staticmethod
     def as_date(df, columns=None, format=None, *args, **kwargs):
         """
         Tranforms the given columns into european dates in the given table
@@ -104,15 +110,15 @@
         columns to be transformed as keys, lenght of expected results as values
         :param lenght: columns to be transformed
         :return:
         """
         columns = columns if isinstance(columns, list) else [columns]
         return Format().with_func(
             df, columns,
-            lambda x, col: x[col].fillna(fillna).astype(int).abs().astype(str).str.pad(
+            lambda x, col: x[col].astype(float).fillna(fillna).astype(int).abs().astype(str).str.pad(
                 width=lenght, fillchar=fillchar, side=side
             )
         )
 
     @staticmethod
     def as_float(df, columns=None, errors='coerce', fill=0.0):
         """
@@ -131,15 +137,15 @@
         Tranforms the given columns into integers
         :param df:
         :param columns:
         :param args:
         :param kwargs:
         :return:
         """
-        return Format().with_func(df, columns, lambda x, column: df[column].astype(int, *args, **kwargs))
+        return Format().with_func(df, columns, lambda x, column: df[column].astype(float).fillna(0).astype(int, *args, **kwargs))
 
     @staticmethod
     def as_string(df, columns=None):
         """
         Tranforms the given columns into strings
         :param df: Table to be transformed
         :param columns: dict
@@ -218,15 +224,15 @@
         ax.set_axisbelow(True)
 
         ax.tick_params(axis='y', colors=font_color)
 
         plt.axvline(x=today_day, color='red', label='axvline - full height', lw=0.5)
 
         # leave_day = (pd.to_datetime('30-06-2023', format='%d-%m-%Y') - proj_start).days
-        # plt.axvline(x=leave_day, color=Colors().green_dtt, label='axvline - full height', lw=0.5)
+        # plt.axvline(x=leave_day, color=Colors().green, label='axvline - full height', lw=0.5)
 
         if sort_by:
             df = df.sort_values(sort_by)
 
         deps = [dep for dep in legend.keys() if dep in df[color_by].drop_duplicates().to_list()]
         locs = {t: len(deps) - i - 1 for i, t in enumerate(deps)}
         leng = 0.8/len(locs.keys())
@@ -277,19 +283,19 @@
         #                    fancybox=False, shadow=False, ncol=len(legend_elements), labelcolor=font_color)
         frame = legend.get_frame()
         frame.set_color(background)
 
         # Setting the background color of the plot
         ax.set_facecolor(background)
         plt.text(
-            0.0, -0.1, 'Deloitte Risk Advisory S.A.  2023', horizontalalignment='left',
+            0.0, -0.1, 'Copyright  2023', horizontalalignment='left',
             verticalalignment='center', transform=ax.transAxes, fontsize=8, fontfamily='Calibri'
         )
         plt.text(
-            1.0, -0.1, 'Lusitania | IFRS 17 | Plano de Projeto' + '    ' + '4', horizontalalignment='right',
+            1.0, -0.1, 'Project' + '    ' + '4', horizontalalignment='right',
             verticalalignment='center', transform=ax.transAxes, fontsize=8, fontfamily='Calibri'
         )
         plt.text(
             0.0, 1.1, 'Ponto de Situao', horizontalalignment='left',
             verticalalignment='center', transform=ax.transAxes, fontsize=21, fontfamily='Calibri'
         )
         plt.text(
@@ -305,15 +311,15 @@
     red = '#E64646'
 
     orange = '#E69646'
     orange_dark = '#B74919'
 
     yellow_functional = '#FFCD00'
 
-    green_dtt = '#86BC25'
+    green = '#86BC25'
     green_accessible = '#26890D'
 
     black = '#000000'
 
     teal = '#34D0C3'
     blue = '#3475D0'
     blue_night = '#36454F'
```

## magicroot/db/_table_types/_addlines.py

```diff
@@ -1,10 +1,10 @@
 import pandas as pd
 from ...db import TableImplementationError
-from ..complete_table import project_cls as CompleteTable
+from ..build_sequence import Table as CompleteTable
 from ...df import discount
 
 
 class Addlines(CompleteTable):
     """
     Adds lines based on config table
     """
@@ -77,15 +77,15 @@
     >>>
     >>>
     >>> AddlinesTest().build(input=downloads, output=downloads, release_to=downloads)
 
     """
 
     var_name = 'Addlines'
-    unchanged = 'old'
+    unchanged = '_old'
     changed = 'new'
     join_validate = 'many_to_one'
 
     @property
     def value_name(self):
         return self.materiality
```

## magicroot/db/_table_types/_fillfrom.py

```diff
@@ -1,10 +1,10 @@
 import pandas as pd
 from ...db import TableImplementationError
-from ..complete_table import project_cls as CompleteTable
+from ..build_sequence import Table as CompleteTable
 
 
 class FillFrom(CompleteTable):
     _fill_from_columns = []
     _fill_from_index_columns = []
 
     def create(self, target, fill_source, *args, **kwargs):
```

## magicroot/df/__init__.py

```diff
@@ -1,24 +1,34 @@
+"""
+All Operations and transformations of pandas Dataframes and Series
+"""
 
-from . import _tec as tec
 
-from . import allocate
+from . import tec as tec
+
+from . import _allocate
 from . import cols
 from . import compare
 from . import compute
 from . import count
 from . import create
 from . import discount
 from . import disc
+from . import interpolate
 from . import format
 from . import group
 from . import index
 from . import melt
 from . import remove
 from . import reshape
 from . import sample
 from . import select
 from . import types
 from . import rep
 from . import dt
+from . import gen
+from . import merge
+from . import re
+from . import str
+from . import find
 
 from .other import *
```

## magicroot/df/add.py

```diff
@@ -1,10 +1,26 @@
 
+def column_name(df, prefix: str = '', suffix='', to_columns=None):
+    """
+    Add sufixes and prefixes to many columns at once
 
-def column_name(df, prefix='', suffix='', to_columns=None):
+
+    .. deprecated:: v0.0.2
+                    to be moved to df.cols.
+
+    :Parameters:
+        df : pandas.Dataframe
+            Dataframe to operate on
+        prefix : str
+            prefix to add
+        suffix : str
+            sufix to add
+        to_columns : list
+            list of columns to operate on
+
+    :Returns:
+        pandas.Dataframe
+            The Dataframe with the names changed
+    """
     if to_columns:
         df.columns = [prefix + column + suffix if column in to_columns else column for column in df.columns]
     return df
-
-
-def column_group_sum(df, ):
-    pass
```

## magicroot/df/cols.py

```diff
@@ -1,18 +1,94 @@
 
 
 def without(df, columns):
+    """
+    Get list of columns of Dataframe except from a given list
+
+    :Parameters:
+        df : pandas.Dataframe
+            Dataframe to operate on
+        to_columns : list
+            Columns to exclude
+
+    :Returns:
+        list, tuple or iterable
+            list of columns of the Dataframe except those specified 'columns' parameter
+
+    Examples
+    ----------
+
+    This has an alias of ``code-block``.
+
+
+    .. code-block:: python
+        :linenos:
+
+        from typing import Iterator
+
+        # This is an example
+        class Math:
+            @staticmethod
+            def fib(n: int) -> Iterator[int]:
+                "Fibonacci series up to n"
+                a, b = 0, 1
+                while a < n:
+                    yield a
+                    a, b = b, a + b
+
+
+        result = sum(Math.fib(42))
+        print("The answer is {}".format(result))
+
+    """
     return [col for col in df.columns if col not in columns]
 
 
+def pull(df, columns, to_the_begin=True):
+    """
+    Pull columns to the begin or the end of the Dataframe
+
+    :Parameters:
+        df : pandas.Dataframe
+            Dataframe to operate on
+        columns : list
+            Columns to pull forward or backwards
+        to_the_begin: Bool, default True
+
+    :Returns:
+        pandas.Dataframe
+            'df' with the columns reordered
+    """
+    if to_the_begin:
+        return df[columns + without(df, columns)]
+    return df[without(df, columns) + columns]
+
+
 def common(df, df_other):
+    """
+    Get list of common columns between two Dataframes
+
+    :param df: *pandas.Dataframe* Dataframe to operate on
+    :param df_other: *pandas.Dataframe* Dataframe to operate on
+    :return: *list* list of columns of the Dataframe except those specified 'columns' parameter
+    """
     return [col for col in df.columns if col in df_other.columns]
 
 
 def split(df, all_except, value_name='value', sep='_', **kwargs):
+    """
+    Split columns based on filter
+
+    :param df: *pandas.Dataframe* Dataframe to operate on
+    :param all_except: *pandas.Dataframe* Dataframe to operate on
+    :param value_name: *pandas.Dataframe* Dataframe to operate on
+    :param sep: *pandas.Dataframe* Dataframe to operate on
+    :param kwargs: *dict of {str: callable or Series}* Dataframe to operate on
+    :return: *list* list of columns of the Dataframe except those specified 'columns' parameter
+    """
     return df.melt(
         id_vars=all_except, value_name=value_name, var_name='col_names'
     ).assign(**kwargs).drop(columns=value_name).melt(
         id_vars=all_except + ['col_names'], value_name='split', var_name='variable'
     ).assign(col_names=lambda x: x['col_names'] + sep + x['variable']).pivot(
         index=all_except,
         columns='col_names',
```

## magicroot/df/disc.py

```diff
@@ -199,19 +199,15 @@
     @staticmethod
     def factor_formula(with_rate, with_maturity):
         return 1 / (1 + with_rate).pow(with_maturity)
 
     def get_rates(self, for_maturities=None):
         if for_maturities is None:
             return self.rate
-        print((for_maturities - self.date).dt.days)
-        print(self.to_dataframe())
         df = self.to_dataframe()
-        print(df)
-        print(pd.DataFrame({'MATURITY_DT': for_maturities}).merge(df, how='left'))
         return pd.DataFrame({'MATURITY_DT': for_maturities}).merge(self.to_dataframe(), how='left')['QUOTE_RT']
 
     def get_act_act_maturities(self, for_maturities=None):
         for_maturities = for_maturities if for_maturities else self.maturity
         return (date_shift(self.date, for_maturities, 'Y') - self.date).days
 
     @staticmethod
@@ -236,23 +232,20 @@
             quote_rate_col='QUOTE_RT', quote_date_col='QUOTE_DT'
     ):
         df = pd.DataFrame({
             maturity_years_col: self.maturity,
             quote_rate_col: self.rate
         })
         df[quote_date_col] = self.date
-        print(df[quote_date_col].head())
-        print(df[maturity_years_col].head())
         df[maturity_dt_col] = date_shift(df[quote_date_col], df[maturity_years_col].astype(int), 'Y')
         df[maturity_days_col] = df[maturity_dt_col] - df[quote_date_col]
         df[maturity_act_act_col] = df[maturity_days_col].dt.days / 365
         return df[[
             quote_date_col, maturity_dt_col, maturity_days_col, maturity_years_col, maturity_act_act_col, quote_rate_col
         ]]
-        print(pd.DataFrame({maturity_dt_col: for_maturities}).merge(df, how='left'))
 
     def shift(self, by):
         return self.to_dataframe()[['MATURITY_DT']].assign(MATURITY_DT=lambda x: x + by).merge(self.to_dataframe())
 
     def forward(self, value):
         numerator = f_factor(self.rate.shift(-1 * value + 1), value + 1)
         denominator = f_factor(self.rate.shift(-1 * value), value)
```

## magicroot/df/dt.py

```diff
@@ -1,34 +1,35 @@
 import pandas as pd
 from datetime import date, timedelta
 import holidays
 import numpy as np
+from . import gen
 
 
 def perc(of, starting_on, ending_on, shift=1, upper=None, lower=None):
     starting_on = starting_on - pd.to_timedelta(shift, unit='D')
     p = (of - starting_on).dt.days / (ending_on - starting_on).dt.days
     return p.clip(upper=upper, lower=lower)
 
 
 def shift(data, shift, unit):
-    data, shift = pd.Series(data), pd.Series(shift)
+    data, shift = gen.coupled_series(data, shift)
     if unit.upper() == 'Y':
         rv = pd.to_datetime(
             (data.dt.year + shift).astype(str) + data.dt.month.astype(str) + data.dt.day.astype(str),
             format='%Y%m%d')
     elif unit.upper() == 'M':
         rv = pd.to_datetime(
             (data.dt.month + shift).astype(str) + data.dt.year.astype(str) + data.dt.day.astype(str),
             format='%m%Y%d')
     else:
         raise NotImplementedError(f'Cannot date shift with arguments of types '
                                   f'{type(data)=}, {type(shift)=}, {type(unit)=}')
 
-    return rv if len(rv) > 1 else rv.iloc[0]
+    return rv
 
 
 def mondays(start_dt, end_dt):  # January 1st
     d = start_dt + timedelta(days=6 - start_dt.weekday())  # First Sunday
     d += timedelta(days=1)  # make it monday
     while d < end_dt:
         yield d
@@ -52,17 +53,14 @@
     while current_date <= end_date:
         # Check if current date is a holiday in Portugal
         if current_date in portugal_holidays:
             yield current_date, portugal_holidays[current_date]
         current_date += timedelta(days=1)
 
 
-def periods_by(on, by, ouput_col='Values'):
-    df = pd.concat([
-        pd.DataFrame({ouput_col: on}).assign(Added=False),
-        pd.DataFrame({ouput_col: by}).assign(Added=True, Period=lambda x: np.arange(x.shape[0]))
-    ])
-    df = df.sort_values([ouput_col, 'Added']).fillna(method='bfill').assign(
-        Period=lambda x: x['Period'].fillna(x['Period'].max() + 1)
-    )
-    df['Period'] = df['Period'].astype(int)
-    return df[~df['Added']].drop(columns='Added')
+def periods(by, on):
+    return lambda df: df.merge(pd.concat([
+        df[[on]].drop_duplicates().assign(Added=False),
+        by.drop_duplicates().frame(on).assign(Added=True, mr_dt_Aux_Period=gen.counting_col())
+    ]).sort_values([on, 'Added']).fillna(method='bfill').assign(
+        mr_dt_Aux_Period=lambda x: x['mr_dt_Aux_Period'].fillna(x['mr_dt_Aux_Period'].max() + 1).astype(int)
+    ).loc[lambda x: ~x['Added']], how='left', validate='m:1', on=on)['mr_dt_Aux_Period']
```

## magicroot/df/format.py

```diff
@@ -1,131 +1,426 @@
 import pandas as pd
+from .. import cls
+from ..errors import TableFormmatingValueError
+
+
+def all(df, format_dic):
+    """
+    Formats a ``pandas.Dataframe`` based on a template defined in ``format_dic``.
+
+    :Parameters:
+        df : pandas.Dataframe
+            Dataframe to operate on
+        format_dic : dic
+            template to format df on.
+        to_the_begin: Bool, default True
+
+    :Returns:
+        pandas.Dataframe
+            ``df`` with the columns formatted.
+
+    :Usages:
+        Formatting with dictionary
+            Let us consider a Dataframe ``df`` defined as below.
+
+        .. code-block:: python
+            :linenos:
+
+            df = pd.DataFrame({
+                'Date': ['2009-10-08', '2013-10-08', '2008-10-08', '2009-10-08'],
+                'Name': ['Neil Caffrey', 'Reddigton', 'Pattrick Jane', 'Harvey Specter'],
+                'n Packages': ['6', '10', '7', '9'],
+                'Package Code': ['480', '40', '208', '64'],
+                'Value': ['8.2', '8.0', '8.1', '8.4']
+            })
+
+        +----+------------+----------------+--------------+----------------+---------+
+        |    | Date       | Name           |   n Packages |   Package Code |   Value |
+        +====+============+================+==============+================+=========+
+        |  0 | 2009-10-08 | Neil Caffrey   |            6 |            480 |     8.2 |
+        +----+------------+----------------+--------------+----------------+---------+
+        |  1 | 2013-10-08 | Reddigton      |           10 |             40 |     8   |
+        +----+------------+----------------+--------------+----------------+---------+
+        |  2 | 2008-10-08 | Pattrick Jane  |            7 |            208 |     8.1 |
+        +----+------------+----------------+--------------+----------------+---------+
+        |  3 | 2009-10-08 | Harvey Specter |            9 |             64 |     8.4 |
+        +----+------------+----------------+--------------+----------------+---------+
+
+        Check the types of the columns in ``df``.
+
+        .. code-block:: python
+            :linenos:
+
+            print(mr.df.types.compared(df=df))
+
+        +--------------+--------+
+        |              | df     |
+        +==============+========+
+        | Date         | object |
+        +--------------+--------+
+        | Name         | object |
+        +--------------+--------+
+        | n Packages   | object |
+        +--------------+--------+
+        | Package Code | object |
+        +--------------+--------+
+        | Value        | object |
+        +--------------+--------+
+
+
+        As we can see the types of the columns in ``df`` are all wrong, ``Date`` is a ``date`` not an ``object``,
+        ``n Packages`` is a ``int`` not an ``object``, ``Package Code`` is a 3 digit ``code`` not an ``object`` and
+        ``Value`` is a ``float`` not an ``object``.
+
+        We fix this by using the function above.
+
+        .. code-block:: python
+            :linenos:
+
+            df = mr.df.format.all(df=df, format_dic={
+                '%Y-%m-%d': 'Date',
+                str: 'Name',
+                int: 'n Packages',
+                3: 'Package Code',
+                float: 'Value'
+            })
+
+
+        +----+---------------------+----------------+--------------+----------------+---------+
+        |    | Date                | Name           |   n Packages |   Package Code |   Value |
+        +====+=====================+================+==============+================+=========+
+        |  0 | 2009-10-08 00:00:00 | Neil Caffrey   |            6 |            480 |     8.2 |
+        +----+---------------------+----------------+--------------+----------------+---------+
+        |  1 | 2013-10-08 00:00:00 | Reddigton      |           10 |            040 |     8   |
+        +----+---------------------+----------------+--------------+----------------+---------+
+        |  2 | 2008-10-08 00:00:00 | Pattrick Jane  |            7 |            208 |     8.1 |
+        +----+---------------------+----------------+--------------+----------------+---------+
+        |  3 | 2009-10-08 00:00:00 | Harvey Specter |            9 |            064 |     8.4 |
+        +----+---------------------+----------------+--------------+----------------+---------+
+
+        Recheck the types of the columns in ``df``.
+
+        +--------------+----------------+
+        |              | df             |
+        +==============+================+
+        | Date         | datetime64[ns] |
+        +--------------+----------------+
+        | Name         | object         |
+        +--------------+----------------+
+        | n Packages   | int32          |
+        +--------------+----------------+
+        | Package Code | object         |
+        +--------------+----------------+
+        | Value        | float64        |
+        +--------------+----------------+
+
+    .. seealso::
+        Related functions
+            see :py:func:`magicroot.df.types.compared`.
+
+        Used functions
+            see :py:func:`magicroot.cls.to_list`.
+    """
+    for ty, cols in format_dic.items():
+        cols = cls.to_list(cols)
+        if ty == float:
+            df = as_float(df, cols)
+        if ty == int:
+            df = as_int(df, cols, errors='ignore')
+        if ty == str:
+            df = as_string(df, cols)
+        if isinstance(ty, int):
+            df = as_code(df, cols, ty)
+        if isinstance(ty, str):
+            df = as_date(df, cols, ty, errors='coerce')
+        if isinstance(ty, tuple):
+            for strg in ty:
+                df = as_date(df, cols, strg, errors='coerce')
+
+    return df
 
 
 def with_func(df, columns, func):
     """
-    Tranforms the given columns based on the given function
-    :param df: Table to be transformed
-    :param columns: columns to be transformed
-    :param func: function that receives the dataframe and the name of the column to be formated
-    :return:
+    Tranforms the given columns based on the given function.
+
+    :Parameters:
+        df : pandas.Dataframe
+            Dataframe to operate on
+        columns : list
+            columns to formatted (if they exist).
+        func: callable
+            function to use in formatting the columns
+
+    :Returns:
+        pandas.Dataframe
+            ``df`` with the columns formatted.
+
+    .. seealso::
+        Related functions
+            see :py:func:`magicroot.df.format.all`.
+
+        Generalization of functions
+            see :py:func:`magicroot.df.format.as_code`.
+
+            see :py:func:`magicroot.df.format.as_date`.
+
+            see :py:func:`magicroot.df.format.as_float`.
+
+            see :py:func:`magicroot.df.format.as_int`.
+
+            see :py:func:`magicroot.df.format.as_string`.
+
     """
     columns = columns if columns is not None else df.columns
     for column in columns:
         if column in df.columns:
-            df = df.assign(**{column: func(df, column)})
-    # return df.assign(**{column: lambda x: func(x, column) for column in columns if column in df.columns})
+            try:
+                df = df.assign(**{column: func(df, column)})
+            except ValueError as e:
+                raise TableFormmatingValueError(f'Column: {column} could not be formatted')
     return df
 
 
-def as_date(df, columns=None, *args, **kwargs):
+_excel_origin = pd.to_datetime('1899-12-30', format='%Y-%m-%d')
+
+
+def as_date(df, columns=None, format=None, *args, **kwargs):
     """
-    Tranforms the given columns into european dates in the given table
-    :param df: Table to be transformed
-    :param columns: columns to be transformed
-    :return:
+    Tranforms the given columns into dates in the given table
+
+    :Parameters:
+        df : pandas.Dataframe
+            Dataframe to operate on
+        columns : list
+            columns to formatted (if they exist).
+        format: str
+            date format of the intput data, see Python `documentation <https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes>`__.
+
+
+
+    :Returns:
+        pandas.Dataframe
+            ``df`` with the columns formatted.
+
+    .. seealso::
+        Related functions
+            see :py:func:`magicroot.df.format.all`.
+
+        Similar to
+            see :py:func:`magicroot.df.format.as_code`.
+
+            see :py:func:`magicroot.df.format.as_date`.
+
+            see :py:func:`magicroot.df.format.as_float`.
+
+            see :py:func:`magicroot.df.format.as_int`.
+
+            see :py:func:`magicroot.df.format.as_string`.
+
     """
+    if format == 'excel':
+        return with_func(
+            df, columns, lambda x, column: pd.to_datetime(
+                df[column], *args, unit='d', origin=_excel_origin, **kwargs
+            )
+        )
+
     return with_func(df, columns, lambda x, column: pd.to_datetime(df[column], *args, **kwargs))
 
 
-def as_set_len_code(df, columns=None, fillna='0'):
+def as_code(df, columns, lenght, fillna='0', fillchar='0', side='left'):
     """
-    Tranforms the given columns into set lenght codes (ex. '001')
-    :param df: Table to be transformed
-    :param columns: dict
-    columns to be transformed as keys, lenght of expected results as values
-    :param lenght: columns to be transformed
-    :return:
-    """
-    columns = columns if columns is not None else df.columns
-    for column, lenght in columns.items():
-        df = with_func(df, [column], lambda x, col: x[col].fillna(fillna).astype(str).str.zfill(lenght))
-    return df
+     Tranforms the given columns into codes (ex: '00023') in the given table
 
+     :Parameters:
+         df : pandas.Dataframe
+             Dataframe to operate on
+         columns : list
+             columns to formatted (if they exist).
+         lenght: int
+             Number of digits in the code.
 
-def dic_transpose(dic, method='values_to_keys'):
-    return_dic = {}
-    if method == 'values_to_keys':
-        for key, val in dic.items():
-            value_list = return_dic[val] if val in return_dic else []
-            return_dic[val] = value_list + [key]
-
-    if method == 'list_values_to_keys':
-        for key, vals in dic.items():
-            for val in vals:
-                return_dic[val] = key
-
-    return return_dic
-
-
-def as_code(df, columns, lenght, fillna='0'):
-    """
-    Tranforms the given columns into set lenght codes (ex. '001')
-    :param df: Table to be transformed
-    :param columns: dict
-    columns to be transformed as keys, lenght of expected results as values
-    :param lenght: columns to be transformed
-    :return:
-    """
-    columns = columns if isinstance(columns, list) else [columns]
-    return with_func(df, columns, lambda x, col: x[col].fillna(fillna).astype(int).astype(str).str.zfill(lenght))
 
+     :Returns:
+         pandas.Dataframe
+             ``df`` with the columns formatted.
 
-def as_code_for_series(s, lenght, fillna='0'):
-    """
-    Tranforms the given columns into set lenght codes (ex. '001')
-    :param df: Table to be transformed
-    :param columns: dict
-    columns to be transformed as keys, lenght of expected results as values
-    :param lenght: columns to be transformed
-    :return:
-    """
-    return s.fillna(fillna).astype(str).str.zfill(lenght)
+     .. seealso::
+         Related functions
+             see :py:func:`magicroot.df.format.all`.
+
+         Similar to
+             see :py:func:`magicroot.df.format.as_code`.
+
+             see :py:func:`magicroot.df.format.as_date`.
+
+             see :py:func:`magicroot.df.format.as_float`.
+
+             see :py:func:`magicroot.df.format.as_int`.
+
+             see :py:func:`magicroot.df.format.as_string`.
+
+     """
+    columns = columns if isinstance(columns, list) else [columns]
+    return with_func(
+        df, columns,
+        lambda x, col: x[col].astype(float).fillna(fillna).astype(int).abs().astype(str).str.pad(
+            width=lenght, fillchar=fillchar, side=side
+        )
+    )
 
 
 def as_float(df, columns=None, errors='coerce', fill=0.0):
     """
-    Tranforms the given columns into floats
-    :param df: Table to be transformed
-    :param columns: dict
-    columns to be transformed as keys, lenght of expected results as values
-    :param lenght: columns to be transformed
-    :return:
-    """
+     Tranforms the given columns into floats in the given table
+
+     :Parameters:
+         df : pandas.Dataframe
+             Dataframe to operate on
+         columns : list
+             columns to formatted (if they exist).
+
+
+     :Returns:
+         pandas.Dataframe
+             ``df`` with the columns formatted.
+
+     .. seealso::
+         Related functions
+             see :py:func:`magicroot.df.format.all`.
+
+         Similar to
+             see :py:func:`magicroot.df.format.as_code`.
+
+             see :py:func:`magicroot.df.format.as_date`.
+
+             see :py:func:`magicroot.df.format.as_float`.
+
+             see :py:func:`magicroot.df.format.as_int`.
+
+             see :py:func:`magicroot.df.format.as_string`.
+
+     """
     return with_func(df, columns, lambda x, column: pd.to_numeric(x[column], errors=errors).fillna(fill))
 
 
 def as_int(df, columns=None, *args, **kwargs):
     """
-    Tranforms the given columns into floats
-    :param df: Table to be transformed
-    :param columns: dict
-    columns to be transformed as keys, lenght of expected results as values
-    :param lenght: columns to be transformed
-    :return:
-    """
-    return with_func(df, columns, lambda x, column: df[column].astype(int, *args, **kwargs))
+     Tranforms the given columns into ints in the given table
+
+     :Parameters:
+         df : pandas.Dataframe
+             Dataframe to operate on
+         columns : list
+             columns to formatted (if they exist).
+
+
+     :Returns:
+         pandas.Dataframe
+             ``df`` with the columns formatted.
+
+     .. seealso::
+         Related functions
+             see :py:func:`magicroot.df.format.all`.
+
+         Similar to
+             see :py:func:`magicroot.df.format.as_code`.
+
+             see :py:func:`magicroot.df.format.as_date`.
+
+             see :py:func:`magicroot.df.format.as_float`.
+
+             see :py:func:`magicroot.df.format.as_int`.
+
+             see :py:func:`magicroot.df.format.as_string`.
+
+     """
+    return with_func(df, columns, lambda x, column: df[column].astype(float).fillna(0).astype(int, *args, **kwargs))
 
 
 def as_string(df, columns=None):
     """
-    Tranforms the given columns into strings
-    :param df: Table to be transformed
-    :param columns: dict
-    columns to be transformed as keys, lenght of expected results as values
-    :param lenght: columns to be transformed
-    :return:
-    """
+     Tranforms the given columns into strings in the given table
+
+     :Parameters:
+         df : pandas.Dataframe
+             Dataframe to operate on
+         columns : list
+             columns to formatted (if they exist).
+
+
+     :Returns:
+         pandas.Dataframe
+             ``df`` with the columns formatted.
+
+     .. seealso::
+         Related functions
+             see :py:func:`magicroot.df.format.all`.
+
+         Similar to
+             see :py:func:`magicroot.df.format.as_code`.
+
+             see :py:func:`magicroot.df.format.as_date`.
+
+             see :py:func:`magicroot.df.format.as_float`.
+
+             see :py:func:`magicroot.df.format.as_int`.
+
+             see :py:func:`magicroot.df.format.as_string`.
+
+     """
     return with_func(df, columns, lambda x, column: df[column].astype(str))
 
 
-def all(df, as_strings=None, as_floats=None, as_set_len_codes=None, as_dates=None):
-    if as_strings is not None:
-        df = as_string(df, columns=as_strings)
-    if as_floats is not None:
-        df = as_float(df, columns=as_floats)
-    if as_set_len_codes is not None:
-        df = as_set_len_code(df, columns=as_set_len_codes)
-    if as_dates is not None:
-        df = as_date(df, columns=as_dates)
+def guarantee(dates=None, ints=None, floats=None, strings=None, error=TypeError):
+    """
+    Raises error if any of the columns are not correctly formatted 
+
+    :Parameters:
+        kwargs : mapping, dict {str: pandas.Dataframe}
+            names and dateframes to compare types.
+
+    :Returns:
+        pandas.Dataframe
+            ``df`` with the index of columns names and one column 
+            per dataframe with the types.
 
+    """
+    dates, ints, floats, strings = cls.to_list(dates, ints, floats, strings)
+    
+    tests = zip((dates, ints, floats, strings), ('datetime', 'int', 'float', 'object'))
+
+    def test(list_of_series, type_str):
+        if list_of_series:
+            for s in list_of_series:
+                try:
+                    assert type_str in str(s.dtypes)
+                except AssertionError:
+                    raise error(f'Column \'{s.name}\' does not have type \'{type_str}\''
+                                f' instead has type \'{str(s.dtypes)}\'')
+
+    for list_of_series, type_str in tests:
+        test(list_of_series=list_of_series, type_str=type_str)
+
+
+def compared(**kwargs):
+    """
+    Compares types of several pandas.Dataframes
+
+    :Parameters:
+        kwargs : mapping, dict {str: pandas.Dataframe}
+            names and dateframes to compare types.
+
+    :Returns:
+        pandas.Dataframe
+            ``df`` with the index of columns names and one column 
+            per dataframe with the types.
+    """
+    columns=kwargs.keys()
+    df = pd.DataFrame({
+        'df_' + str(i + 1): df.dtypes for i, df in enumerate(kwargs.values())
+    })
+    df.columns = columns if columns is not None else df.columns
     return df
+
+
```

## magicroot/df/group.py

```diff
@@ -37,12 +37,27 @@
 
 
 def count(columns, by, *args, **kwargs):
     return _base(columns, by, func='count', *args, **kwargs)
 
 
 def apply(columns, by, func, *args, **kwargs):
+    """
+    Create column based on Dataframe shape with the result of a groupby apply
+
+    :Parameters:
+        columns : list
+            Columns to return, result of apply
+        by : list
+            Columns to use for grouping
+        func: callable
+            Function to pass to the ''apply''
+
+    :Returns:
+        callable(pandas.Dataframe)
+            A function that can be applied to a Dataframe
+    """
     return lambda x: x[by + columns].groupby(by, group_keys=False, *args, **kwargs).apply(func)[columns]
 
 
 def pattern(columns, by, *args, **kwargs):
     return apply(columns, by, func=lambda x: x/x.sum(numeric_only=True), *args, **kwargs)
```

## magicroot/df/melt.py

```diff
@@ -8,14 +8,20 @@
 def date_interval(
         df, begin_dt_column, end_dt_column,
         freq='M',
         period_column='period',
         begin_period_column='begin_period',
         end_period_column='end_period',
         *args, **kwargs):
+    """
+
+    .. deprecated:: v0.0.2
+                    to be moved to :py:func:`magicroot.df.tec.melt_by_dates`.
+
+    """
     df = df.reset_index(drop=True)
     offset = pd.offsets.MonthEnd() if freq == 'M' else pd.offsets.YearEnd()
     return format.as_date(df[[begin_dt_column, end_dt_column]], columns=None, *args, **kwargs).apply(
         lambda x: pd.Series(
             pd.date_range(
                 start=x[begin_dt_column],
                 end=(x[end_dt_column] - pd.to_timedelta(1, unit='day')) + offset,
```

## magicroot/df/plot.py

```diff
@@ -1,11 +1,10 @@
 
 # from .. import df
 import pandas as pd
-import Modelo_de_Dados_Lusitania.src.modelo_de_dados.base._modules.magicroot as mr
 from matplotlib.patches import Patch
 import matplotlib.pyplot as plt
 import numpy as np
 import datetime as dt
 from datetime import timedelta
 import matplotlib.colors as mcolors
 from .dt import mondays, specific_weekday, portugal_holidays
@@ -170,19 +169,19 @@
     width = bb.width
     height = bb.height
     pos = axs[0].get_position()
 
     print(f'{width=}')
     print(f'{height=}')
     fig.text(
-        0.0 + pos.x0 - 0.02, 0.0, 'Deloitte Risk Advisory S.A.  2023', horizontalalignment='left',
+        0.0 + pos.x0 - 0.02, 0.0, 'Copyright  2023', horizontalalignment='left',
         verticalalignment='center', fontsize=8, fontfamily='Calibri'
     )
     fig.text(
-        1.0, 0.0, 'Lusitania | IFRS 17 | Plano de Projeto' + '    ' + str(page), horizontalalignment='right',
+        1.0, 0.0, 'Project' + '    ' + str(page), horizontalalignment='right',
         verticalalignment='center', fontsize=8, fontfamily='Calibri'
     )
 
     fig.text(
         0.0 + pos.x0 - 0.02, 1.0, 'Ponto de Situao', horizontalalignment='left',
         verticalalignment='center', fontsize=21, fontfamily='Calibri'
     )
@@ -199,15 +198,15 @@
     red = '#E64646'
 
     orange = '#E69646'
     orange_dark = '#B74919'
 
     yellow_functional = '#FFCD00'
 
-    green_dtt = '#86BC25'
+    green = '#86BC25'
     green_accessible = '#26890D'
 
     black = '#000000'
 
     teal = '#34D0C3'
     blue = '#3475D0'
     blue_night = '#36454F'
```

## magicroot/df/rep.py

```diff
@@ -1,10 +1,16 @@
 
 
 def common_columns(left, right):
+    """
+
+    .. deprecated:: v0.0.2
+                    to be moved to :py:func:`magicroot.df.cols.common`.
+
+    """
     return [col for col in left.columns if col in right.columns]
 
 
 def common_lines(left, right, names=('left', 'right'), col_name='In_Table'):
     common_cols = common_columns(left, right)
     df = left[common_cols].drop_duplicates().merge(
         right[common_cols].drop_duplicates(), how='outer', indicator=col_name)
```

## magicroot/df/types.py

```diff
@@ -1,8 +1,9 @@
 from . import compare
+from . import gen
 
 
 def compared(**kwargs):
     return compare.types(*kwargs.values(), columns=kwargs.keys())
 
 
 def different(*args, **kwargs):
```

## magicroot/fs/__init__.py

```diff
@@ -1,3 +1,6 @@
-from . import _discount as disc
-from ._balance_sheet import BalanceSheet
+"""
+Module to help in finatial services mainly discounting and Balance Sheets
+"""
 
+from ._balance_sheet import BalanceSheet
+from . import disc
```

## magicroot/fs/_balance_sheet.py

```diff
@@ -1,46 +1,144 @@
 import pandas as pd
 from dataclasses import dataclass
-
+from .. import df as mr
+import regex as re
+from ..time import function as time_function
 
 @dataclass
 class BalanceSheet:
     period: pd.Timestamp
     accounts: pd.Series
     balances: pd.Series
-    agregations: pd.Series = None
+    others: pd.DataFrame = None
+    descriptions: pd.DataFrame = None
+    dimensions: pd.DataFrame = None
+    name: str = None
 
     def __post_init__(self):
-        df = self.df.groupby(['accounts', 'agregations']).sum().reset_index()
-        print(df.head())
-        self.accounts = df['accounts']
-        self.balances = df[self.period]
-        self.agregations = df[self.agregations if self.agregations is not None else self.accounts]
-
-        self.check_balanced()
+        self.accounts, self.balances = mr.gen.coupled_series(self.accounts.astype(str), self.balances)
+        self.name = self.name if self.name is not None else self.period
+        self.split_descriptions_from_dimentions()
+        # self.group()
+        self.balanced_on_acc()
+
+    def split_descriptions_from_dimentions(self):
+        bl = self.others.copy()
+        bl['accounts'] = self.accounts
+        df = bl.groupby('accounts').nunique()
+        x = pd.DataFrame(df.max(), columns=['value'])
+        self.descriptions = bl[x[x['value'] == 1].index.to_list()]
+        self.dimensions = bl[[col for col in x.index if col not in x[x['value'] == 1].index.to_list()]]
 
-    def check_balanced(self):
+    def balance(self):
         assert self.balances.sum() < 0.01
 
-    def post(self, value, credit, debit):
-        if len(self.accounts[self.accounts == credit]) != 1:
-            raise ValueError(f'\'credit\' filter has not produced single account, produced: {self.accounts[self.accounts == credit]}')
+    def balanced_on_acc(self, acc='__control__'):
+        self[acc] = -self.balances[self.accounts != acc].sum()
 
-        if len(self.accounts[self.accounts == debit]) != 1:
-            raise ValueError('\'dedit\' filter has not produced single account')
+    def to_frame_agg(self):
+        return pd.concat([
+            self.accounts.to_frame('accounts'),
+            self.descriptions,
+            self.balances.to_frame(self.name)
+        ], axis=1).groupby(['accounts'] + self.descriptions.columns.to_list(), dropna=False).sum()
+
+    def to_frame_level(self, level=2):
+        return self.to_frame_agg().reset_index()[['accounts', self.name]].assign(
+            accounts=lambda x: x['accounts'].str[:level]).groupby('accounts').sum()
+
+    def to_frame(self, pat=None):
+        bl = pd.concat([
+            self.accounts.to_frame('accounts'),
+            self.descriptions,
+            self.dimensions,
+            self.balances.to_frame(self.name)
+        ], axis=1)
+        bl = bl[self.pattern_filter(pat)]
+
+        return bl.set_index(['accounts'] + self.descriptions.columns.to_list() + self.dimensions.columns.to_list())
+
+    def pattern_filter(self, pat=None):
+        if pat is None:
+            return self.accounts.apply(lambda x: True)
+        return self.accounts.apply(lambda x: bool(re.fullmatch(pat, x)))
+
+    def add_descriptions_by_patterns(self, patterns, descriptions):
+        self.descriptions['pat'] = ''
+        for pat in patterns.drop_duplicates().astype(str):
+            self.descriptions = self.descriptions.assign(
+                pat=self.descriptions['pat'].mask(self.accounts.astype(str).apply(lambda x: bool(re.fullmatch(pat, x))), pat)
+            )
+        self.descriptions = self.descriptions.merge(
+            pd.concat([descriptions, patterns.to_frame('pat')], axis=1).groupby('pat', dropna=False).first().reset_index(),
+            how='left', validate='m:1'
+        ).drop(columns='pat')
 
-        self.balances.loc[self.accounts == credit] -= value
-        self.balances.loc[self.accounts == debit] += value
+    @property
+    def frame(self):
+        return pd.DataFrame({'accounts': self.accounts, self.period: self.balances})
 
-        self.check_balanced()
+    def from_frame(self, df):
+        self.accounts = df.accounts
+        self.balances = df[self.period]
 
-    @property
-    def df(self):
-        return pd.DataFrame({'accounts': self.accounts, 'agregations': self.agregations, self.period: self.balances})
+    def agg(self, accounts_level=2):
+        return self.frame.assign(
+            accounts=lambda x: x['accounts'].str[:accounts_level]
+        ).groupby('accounts').sum().reset_index()
+
+    def group(self):
+        df = self.frame.groupby(['accounts']).sum().reset_index()
+        self.accounts = df['accounts']
+        self.balances = df[self.period]
+
+    def __getitem__(self, item):
+        bl = self.to_frame(pat=item).reset_index()
+        return BalanceSheet(
+            period=self.period, accounts=bl.accounts, name=self.name,
+            balances=bl[self.name], others=bl[mr.cols.without(bl, [self.name, 'accounts'])]
+        )
+
+    def __setitem__(self, key, value):
+        fltr = self.pattern_filter(key)
+        self.balances.loc[fltr] = value
+        print(f'len of {key} is {len(self.balances.loc[fltr])}')
+        if len(self.balances.loc[fltr]) == 0:
+            self.accounts.loc[len(self.accounts)] = key
+            self.balances.loc[len(self.balances)] = value
 
     def __sub__(self, other):
+        joined = self.to_frame().reset_index().merge(other.to_frame().reset_index(), how='outer').assign(
+                balance=lambda x: x[self.name].fillna(0) - x[other.name].fillna(0)
+            )
         return BalanceSheet(
-            period=self.period, accounts=self.accounts,
-            balances=self.df.merge(other.df, how='left').assign(balance=lambda x: x[self.period] - x[other.period])['balance']
+            period=self.period, accounts=joined.accounts,
+            balances=joined['balance'], name=str(self.name) + ' - ' + str(other.name),
+            others=joined[mr.cols.without(joined, [self.name, 'accounts'])]
         )
 
+    def copy(self, name=None):
+        return BalanceSheet(
+            period=self.period, accounts=self.accounts, balances=self.balances, others=self.others,
+            name=name or self.name
+        )
+
+    def open(self, account, name):
+        bl = self.copy()
+        bl[account] = 0
+        return bl
+
+    def close(self, account, beneficiary, name):
+        bl = self.copy()
+        value = bl[account].sum()
+        return bl.post(bl[account], credit=account, debit=beneficiary)
+
+    def post(self, value, credit, debit):
+        if len(self.accounts[self.accounts == credit]) != 1 and len(self.accounts[self.accounts == debit]) != 1:
+            raise ValueError(f'\'credit\' and \'dedit\' filter has not produced single account')
+
+        self.balances.loc[self.accounts == credit] -= value
+        self.balances.loc[self.accounts == debit] += value
+
+        self.check_balanced()
+
 # Use pandas pivot_table
```

## magicroot/os/file.py

```diff
@@ -1,11 +1,11 @@
 from .parcers import *
 from .navigator import Navigator
 from .parcer_base import Parser
-from ..beta.fileleaf import extensions
+from .._beta.fileleaf import extensions
 import shutil
 import logging
 
 log = logging.getLogger('MagicRoot.databranch.os.file')
 
 
 class ParcerNotFound(FileNotFoundError):
```

## magicroot/os/folder.py

```diff
@@ -1,10 +1,10 @@
 import os
 import shutil
-from ..beta import fileleaf as fl
+from .._beta import fileleaf as fl
 import zipfile
 import ntpath
 import datetime
 from .navigator import Navigator
 from .file import File
 import logging
 from ..log import logged
```

## magicroot/os/navigator.py

```diff
@@ -1,14 +1,14 @@
 import os
 import re
 import getpass
 from fuzzywuzzy import process
 import ntpath
 # from .file import File
-from ..beta.fileleaf import extensions
+from .._beta.fileleaf import extensions
 import subprocess
 import logging
 
 log = logging.getLogger('MagicRoot.databranch.os.navigator')
 
 
 class PathNotFound(FileNotFoundError):
```

## magicroot/os/parcer_base.py

```diff
@@ -1,10 +1,9 @@
 import os
 import json
-from Modelo_de_Dados_Lusitania.src.modelo_de_dados.base._modules.magicroot._saved.locator import path as base_settings_path
 import pandas as pd
 import logging
 
 log = logging.getLogger(__name__)
 pd.set_option('display.max_rows', None)
 pd.set_option('display.max_columns', None)
 pd.set_option('display.width', None)
```

## Comparing `magicroot-0.1.83.dist-info/LICENSE` & `magicroot-0.1.84.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `magicroot-0.1.83.dist-info/METADATA` & `magicroot-0.1.84.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: magicroot
-Version: 0.1.83
+Version: 0.1.84
 Summary: Python like magic
 Home-page: https://github.com/HephaestusGodOfFire/magicroot
 Author: HephaestusGodOfFire
 Author-email: author@example.com
 License: UNKNOWN
 Project-URL: Bug Tracker, https://github.com/HephaestusGodOfFire/magicroot/issues
 Platform: UNKNOWN
```

